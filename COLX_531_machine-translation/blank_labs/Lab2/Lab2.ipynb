{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2 - Machine Translation - MDS Computational Linguistics\n",
    "\n",
    "### Assignment Topics\n",
    "- seq2seq Models\n",
    "- Grid Search vs. Random Search for Hyperparameters Tuning\n",
    "\n",
    "\n",
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.2.0) \n",
    "- Jupyter (latest)\n",
    "\n",
    "### Submission Info.\n",
    "- Due Date: March 7, 2020, 18:00:00 (Vancouver time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset\n",
    "\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 77\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Seq2Seq Review\n",
    "\n",
    "\n",
    "### 1.1 Warm Up\n",
    "rubric={reasoning:2}\n",
    "\n",
    "As a quick warm up. Take a minute to review the code from the tutorial and identify hyper parameters related to the three sections of code: Encoder, Decoder, and Seq2Seq. You can just copy and paste these hyper parameters into the box below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Paste the relevant hyper parameters in each section:\n",
    "Encoder:\n",
    "\n",
    "Decoder:\n",
    "\n",
    "Seq2Seq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim,n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "       \n",
    "        # outputs are always from the top hidden layer, if bidirectional outputs are concatenated.\n",
    "        # outputs shape [sequence_length, batch_size, hidden_dim * num_directions]\n",
    "        # hidden is of shape [num_layers * num_directions, batch_size, hidden_size]\n",
    "        # cell is of shape [num_layers * num_directions, batch_size, hidden_size]\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, dec_hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "             \n",
    "        # input is of shape [batch_size]\n",
    "        # hidden is of shape [n_layer * num_directions, batch_size, hidden_size]\n",
    "        # cell is of shape [n_layer * num_directions, batch_size, hidden_size]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        # input shape is [1, batch_size]. reshape is needed rnn expects a rank 3 tensors as input.\n",
    "        # so reshaping to [1, batch_size] means a batch of batch_size each containing 1 index.\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]    \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        \n",
    "        # output shape is [sequence_len, batch_size, hidden_dim * num_directions]\n",
    "        # hidden shape is [num_layers * num_directions, batch_size, hidden_dim]\n",
    "        # cell shape is [num_layers * num_directions, batch_size, hidden_dim]\n",
    "\n",
    "        # sequence_len and num_directions will always be 1 in the decoder.\n",
    "        # output shape is [1, batch_size, hidden_dim]\n",
    "        # hidden shape is [num_layers, batch_size, hidden_dim]\n",
    "        # cell shape is [num_layers, batch_size, hidden_dim]\n",
    "        \n",
    "        prediction = self.fc_out(hidden.squeeze(0)) # linear expects as rank 2 tensor as input\n",
    "        # predicted shape is [batch_size, output_dim]\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    ''' This class contains the implementation of complete sequence to sequence network.\n",
    "    It uses to encoder to produce the context vectors.\n",
    "    It uses the decoder to produce the predicted target sentence.\n",
    "    Args:\n",
    "        encoder: A Encoder class instance.\n",
    "        decoder: A Decoder class instance.\n",
    "    '''\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src is of shape [sequence_len, batch_size]\n",
    "        # trg is of shape [sequence_len, batch_size]\n",
    "        # if teacher_forcing_ratio is 0.5 we use ground-truth inputs 50% of time and 50% time we use decoder outputs.\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # to store the outputs of the decoder\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # context vector, last hidden and cell state of encoder to initialize the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            use_teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            input = (trg[t] if use_teacher_force else top1)\n",
    "\n",
    "        # outputs is of shape [sequence_len, batch_size, output_dim]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Initialization\n",
    "\n",
    "\n",
    "### 2.1 seq2seq weight initialization\n",
    "rubric={accuracy:7}\n",
    "\n",
    "In the tutorial, we used a Normal distribution for our weight initialization.\n",
    "\n",
    "On the same translation task, compare how this initialization does with using a Uniform Distribution as well as initializing with weights of Zero.  Report the BLEU-4 score of each of the models based on training using these different initializations.\n",
    "\n",
    "(We can load the French and English pickle files that you saved before to save some time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load your pickles\n",
    "with open(\"./drive/My Drive/Colab Notebooks/ckpt/TRG.Field\",\"rb\")as f:\n",
    "     TRG = pickle.load(f)\n",
    "\n",
    "with open(\"./drive/My Drive/Colab Notebooks/ckpt/SRC.Field\",\"rb\")as f:\n",
    "     SRC = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feel free to change by commenting out and replacing parts\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training procedure goes here as needed. (can use the tutorial as a guide)\n",
    "#BE SURE TO USE THE SAME SEED EACH TIME YOU RUN!\n",
    "manual_seed = 77\n",
    "torch.manual_seed(manual_seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fill in\n",
    "Normal Intialization BLEU-4:\n",
    "Uniform Initialization BLEU-4:\n",
    "Zero Initialization BLEU-4:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Hyper Parameters\n",
    "\n",
    "### 3.1 Hyper parameter exploration\n",
    "rubric={accuracy:7}\n",
    "\n",
    "Since you should have built a network for 2.1 test the network using the following hyper parameters configurations and report BLEU-4 for each configuration."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Configuration 1:\n",
    "Learning rates: 0.02\n",
    "Teacher Forcing: 0.25\n",
    "Optimizer: Adam[ Betas= (.9,.999), epsilon=2e-8]\n",
    "\n",
    "Configuration 2:\n",
    "Learning rates: N/A\n",
    "L2 regularization: 0.005\n",
    "Teacher Forcing: 0.5\n",
    "Optimizer: AdaDelta   (This is like Adam, but doesn't require setting an initial learning rate)\n",
    "\n",
    "Configuration 3:\n",
    "Learning rates: 0.1\n",
    "Teacher Forcing: 0.7\n",
    "Optimizer: SGD [momentum= 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Conceptual Questions\n",
    "\n",
    "### 4.1 Sequence Length\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Seq2Seq models have flexibility in terms of the sequence length they can handle. Explain briefly. (2-3 sentences are enough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Same language?\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Seq2seq models aren't just limited to translation, consider the task of simplifying sentences to make them easier to read. You could do this by training a seq2seq model on a say a parallel corpus that incorporates English Wikipedia articles aligned to Simple English Wikipedia articles. List two other applications of applying a seq2seq model that could take input in the same language as its output. Make sure you explain each application in 1-2 sentences.  (Assume you could make/find the approrpriate aligned corpuses to make this feasible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Bidirectional?\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Would bidirectional LSTMs/RNNs work to build an Encoder/Decoder model? Why/Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Weights\n",
    "rubric={reasoning:3}\n",
    "\n",
    "There are several different ways to set the weights of different layers in a NN. We've seen Uniform, Normal distributions as well as setting them to some constant value. [Glorot & Bengio (2010)](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf?source=post_page---------------------------) investigate how the initialization of these layers can greatly impact the performance of deep neural networks. Take a few minutes to *SKIM* the abstract and then *SKIM* the bullet points in the conclusion and write a few sentences summarizing takeaways that you can use in practice.\n",
    "\n",
    "\n",
    "Glorot, X., & Bengio, Y. (2010, March). Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
