{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3 - Machine Translation - MDS Computational Linguistics\n",
    "\n",
    "### Assignment Topics\n",
    "- Seq2seq with attention\n",
    "- Evaluation metric\n",
    "\n",
    "\n",
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.2.0) \n",
    "- Jupyter (latest)\n",
    "\n",
    "### Submission Info.\n",
    "- Due Date: March 15, 2020, 18:00:00 (Vancouver time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset\n",
    "\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seed of randomization and working device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 77\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention! Tidy Submission\n",
    "\n",
    "rubric={mechanics:3}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded.\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions).\n",
    "- You should not use this notebook (i.e., Lab3.ipynb) to train your model on Colab. Colab may change the layout of the jupyter notebook, and then we cannot grade on your notebook, the system will miss your grade!\n",
    "- We provide another jupyter notebook (i.e., `Lab3_exp.ipynb`) for you. You can load `Lab3_exp.ipynb` to Colab and run your experiments in this jupyter notebook. \n",
    "- Please download `Lab3_exp.ipynb` from Colab and include it in your final submission. \n",
    "- Some comments in your code will help us grade. Please use heading, comments, and mardown notations to organize your code. \n",
    "- Please feel free to add cells in `Lab3_exp.ipynb`.\n",
    "- You don't need to submit your checkpoints.\n",
    "- You can reuse any scripts of lab tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the questions of this lab, we continue to use the English-French bilingual corpus of [Multi30k](https://github.com/multi30k/dataset) dataset that we used in lab2 and tutorials. Our task is to `translate text from French language to English language`. All your model should be trained on `train_eng_fre.tsv`, validated on `val_eng_fre.tsv`, and tested on `test_eng_fre.tsv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Seq2Seq Variant\n",
    "\n",
    "In last week, we used a **uni-directional LSTM Encoder** to compress the information of a source language into two context representation vectors of a fixed length (i.e., the final hidden and cell states). Then, we use the final hidden and cell states to initialize the hidden and cell states of uni-directional LSTM Decoder. However, the capability of these representations can be limited. They can easily forget the earlier information of a long sequence and co-reference relationships. Before introducing the attention mechanism, we can also use some tricks to solve the issue of context **information bottleneck** problem. \n",
    "\n",
    "In this exercise, please write a script to implement the following tricks in **a single seq2seq model**:\n",
    "1. Use a **bi-directional LSTM** as the **Encoder** to get the context representation of the source sentence. \n",
    "\n",
    "2. Instead of using the final hidden and cell states of the bi-directional encoder to initialize the uni-directional decoder, (A) for $h_0$ use **the mean of all hidden states** and (B) for $c_0$ use the **final cell state** of the bi-directional encoder. \n",
    "\n",
    "Combine 1 & 2 in **a single seq2seq model**.\n",
    "\n",
    "**Instruction:**\n",
    "- Please paste your experiment codes to answer the corresponding question below.\n",
    "- You should train your model with the following hyper-parameters:\n",
    "```\n",
    "INPUT_DIM = 6004\n",
    "OUTPUT_DIM = 6004\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_LAYERS = 1\n",
    "BI_DIRECTION = True\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = XXXXX (you should figure out this hyper-parameter). \n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.3\n",
    "TEACH_FORCING_RATE = 0.5\n",
    "LEARNING_RT = 0.001\n",
    "MAX_EPOCH = 15\n",
    "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n",
    "```\n",
    "- You should use `init_weights()` function from this week tutorial to initialize model with normal distribution with `mean=0` and `std=0.01`. \n",
    "- Your seed of randomization should be 77 (i.e., manual_seed = 77). \n",
    "- You should use `nn.CrossEntropyLoss()` loss function and ignore `<pad>` tokens.\n",
    "- You should save the model checkpoint at the end of each epoch. You also need to save your vocabularies.\n",
    "- You should use a different checkpoint directory to avoid overwriting previous models. \n",
    "- Then, you load the best checkpoint and evaluate it on TEST set. \n",
    "- You should keep your vocabularies and best checkpoints. We will use them in Exercise 3 (Error analysis). \n",
    "\n",
    "**Hints:**\n",
    "- Although the encoder is bi-directional LSTM, the decoder must be a uni-directional LSTM.\n",
    "- This exercise is more related to last tutorial (i.e., week 2). \n",
    "- The last hidden state of the LSTM is `h_n` of shape (num_layers * num_directions, batch, hidden_size).\n",
    "- The last cell state of the LSTM is `c_n` of shape (num_layers * num_directions, batch, hidden_size).\n",
    "- All the hidden states from the last LSTM layer is `output` of shape (seq_len, batch, num_directions * hidden_size).\n",
    "- The initialization states (i.e., $s_0$,$c_0$) of Decoder must match the dimension of Decoder. Namely, you should give a appropriate number of `DEC_HID_DIM` via analyzing the relation between tensor shapes. \n",
    "- You can use `print(XXX.shape)` to check the shape of your tensor. If the tensor shape doesn't match the desired shape of tensor, you should reshape it using `.view(), .squeeze(), .unsqueeze() or .permute() function.`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To facilitate your model evaluation, we provide a `inference()` function which calculates BLEU score based on a test corpus (test_eng_fre.tsv).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, file_name, src_vocab, trg_vocab, attention=False, max_trg_len = 64):\n",
    "    '''\n",
    "    Function for translation inference\n",
    "\n",
    "    Input: \n",
    "    model: translation model;\n",
    "    file_name: the directoy of test file that the first column is target reference, and the second column is source language;\n",
    "    trg_vocab: Target torchtext Field\n",
    "    attention: the model returns attention weights or not.\n",
    "    max_trg_len: the maximal length of translation text (optinal), default = 64\n",
    "\n",
    "    Output:\n",
    "    Corpus BLEU score.\n",
    "    '''\n",
    "    from nltk.translate.bleu_score import corpus_bleu\n",
    "    from nltk.translate.bleu_score import sentence_bleu\n",
    "    from torchtext.data import TabularDataset\n",
    "    from torchtext.data import Iterator\n",
    "\n",
    "    # convert index to text string\n",
    "    def convert_itos(convert_vocab, token_ids):\n",
    "        list_string = []\n",
    "        for i in token_ids:\n",
    "            if i == convert_vocab.vocab.stoi['<eos>']:\n",
    "                break\n",
    "            else:\n",
    "                token = convert_vocab.vocab.itos[i]\n",
    "                list_string.append(token)\n",
    "        return list_string\n",
    "\n",
    "    test = TabularDataset(\n",
    "      path=file_name, # the root directory where the data lies\n",
    "      format='tsv',\n",
    "      skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "      fields=[('TRG', trg_vocab), ('SRC', src_vocab)])\n",
    "\n",
    "    test_iter = Iterator(\n",
    "    dataset = test, # we pass in the datasets we want the iterator to draw data from\n",
    "    sort = False,batch_size=128,\n",
    "    sort_key=None,\n",
    "    shuffle=False,\n",
    "    sort_within_batch=False,\n",
    "    device = device,\n",
    "    train=False\n",
    "    )\n",
    "  \n",
    "    model.eval()\n",
    "    all_trg = []\n",
    "    all_translated_trg = []\n",
    "\n",
    "    TRG_PAD_IDX = trg_vocab.vocab.stoi[trg_vocab.pad_token]\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(test_iter):\n",
    "\n",
    "            src = batch.SRC\n",
    "            #src = [src len, batch size]\n",
    "\n",
    "            trg = batch.TRG\n",
    "            #trg = [trg len, batch size]\n",
    "\n",
    "            batch_size = trg.shape[1]\n",
    "\n",
    "            # create a placeholder for traget language with shape of [max_trg_len, batch_size] where all the elements are the index of <pad>. Then send to device\n",
    "            trg_placeholder = torch.Tensor(max_trg_len, batch_size)\n",
    "            trg_placeholder.fill_(TRG_PAD_IDX)\n",
    "            trg_placeholder = trg_placeholder.long().to(device)\n",
    "            if attention == True:\n",
    "                output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
    "            else:\n",
    "                output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
    "            # get translation results, we ignor first token <sos> in both translation and target sentences. \n",
    "            # output_translate = [(trg len - 1), batch, output dim] output dim is size of target vocabulary.\n",
    "            output_translate = output[1:]\n",
    "            # store gold target sentences to a list \n",
    "            all_trg.append(trg[1:].cpu())\n",
    "\n",
    "            # Choose top 1 word from decoder's output, we get the probability and index of the word\n",
    "            prob, token_id = output_translate.data.topk(1)\n",
    "            translation_token_id = token_id.squeeze(2).cpu()\n",
    "\n",
    "            # store gold target sentences to a list \n",
    "            all_translated_trg.append(translation_token_id)\n",
    "      \n",
    "    all_gold_text = []\n",
    "    all_translated_text = []\n",
    "    for i in range(len(all_trg)): \n",
    "        cur_gold = all_trg[i]\n",
    "        cur_translation = all_translated_trg[i]\n",
    "        for j in range(cur_gold.shape[1]):\n",
    "            gold_convered_strings = convert_itos(trg_vocab,cur_gold[:,j])\n",
    "            trans_convered_strings = convert_itos(trg_vocab,cur_translation[:,j])\n",
    "\n",
    "            all_gold_text.append(gold_convered_strings)\n",
    "            all_translated_text.append(trans_convered_strings)\n",
    "\n",
    "    corpus_all_gold_text = [[item] for item in all_gold_text]\n",
    "    corpus_bleu_score = corpus_bleu(corpus_all_gold_text, all_translated_text)  \n",
    "    return corpus_bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inference()` function will take five variables `model, file_name, trg_vocab,attention, and max_trg_len` as inputs and return a corpus cumulative BLEU-4 score. Here is a use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use case\n",
    "print(inference(model_best, \"./drive/My Drive/Colab Notebooks/eng-fre/test_eng_fre.tsv\", SRC, TRG, True, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Please paste your full training log here. Which epoch is the best?\n",
    "rubric={accuracy:2}\n",
    "Your log should look like this:\n",
    "```\n",
    "Epoch: 01 | Time: 1m 25s\n",
    "\tTrain Loss: 4.293 | Train PPL:  73.188\n",
    "\t Val. Loss: 4.263 |  Val. PPL:  71.012 \n",
    "   ............\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**\n",
    "**My best model is trained with XX epochs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Your log goes here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Please report the cumulative BLEU-4 score on test set (i.e., `test_eng_fre.tsv`) via corpus_bleu() function.\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Hint: You can use `inference()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here**\n",
    "\n",
    "**My best model obtains XX.XX cumulative BLEU-4 score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please paste your code for the corresponding questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pleae revise the following code to build the appropriate vocabularies:\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "TRG.build_vocab(train)\n",
    "SRC.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 You may need to revise `class Encoder`. Please show your code for `class Encoder`:\n",
    "rubric={accuracy:2, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4  You may need to revise `class Decoder`. Please show your code for `class Decoder`:\n",
    "rubric={accuracy:2, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 You may need to revise `class Seq2Seq`. Please show your code for `class Seq2Seq`:\n",
    "rubric={accuracy:2, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 You may need to revise the code of instantiating classes. Please show your code for instantiation:\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Seq2Seq with varient of attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention mechanisms boost the performance of deep learning models in machine translation and classification tasks, helping models select informative context to form the context representation. They also provide meaningful interpretation of the behavior of black-box deep learning models. In the tutorial of this week, we implemented the **concatenative/additive attention** which was initially proposed by [Bahdanau et al. (2015)](https://arxiv.org/pdf/1409.0473.pdf) to help memorize long source sentences in neural machine translation model. Additive attention computes the attention score in the following way, $e_{ij} = v_a tanh (W_a [s_{i-1};h_j;]) \\in \\mathcal{R}$ where $W_a \\in \\mathcal{R}^{h\\times 2h}$ and $v_a \\in \\mathcal{R}^{1\\times h}$.\n",
    "\n",
    "In the followup work, [Luong et al. (2015)](https://arxiv.org/pdf/1508.04025.pdf) examines two type of attention-based models (i.e., **global attetnion and local attention**) with effective classes of attention alignment functions (e.g., concat product, dot product, and general product). Generally, **a global approach** always attends to all source tokens, and **a local approach** only looks at a subset of source tokens at a time. [Luong et al. (2015)](https://arxiv.org/pdf/1508.04025.pdf) report the performances of models under different settings. The results show the model that is trained with **global attention with dot product alignment function** is better than MLP model that is trained with **global attention and concat product alignment function**. We briefly studied **global attention and concat product alignment function** as **Dot-Product/Multiplicative** attention in the tutorial.     \n",
    "\n",
    "In this exercise, you need to write code to implement **global attention with dot product alignment function** (**Dot-Product/Multiplicative**) from [Luong et al. (2015)](https://arxiv.org/pdf/1508.04025.pdf) to solve our translation task. \n",
    "\n",
    "Hint:\n",
    "- This exercise is more related to the tutorial of this week (i.e., week 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Warm Up\n",
    "rubric={accuracy:8}\n",
    "\n",
    "As a quick warm-up, take a minute to review **the code from the tutorial of this week** and identify the code to answer corresponding. You can copy and paste the code from the tutorial into the box below. You don't need to write any of your code in this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bahdanau et al., use **global attention** with one alignment function, the **concatenative/additive attention**. This will take in the previous hidden state of the decoder, $s_{t-1} \\in \\mathcal{R}^h$, and all of the stacked hidden states from the encoder, $H \\in \\mathcal{R}^{T\\times h}$. First, we calculate the *energy* between the previous decoder hidden state (i.e., $s_{t-1}$) and the encoder hidden states (i.e., $H$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is `repeat` the previous decoder hidden state $T-1$ times to obtain a matrix, $S_{t-1} \\in \\mathcal{R}^{T \\times h}$.\n",
    "\n",
    "**Please paste the line(s) that perform this `repeat` operation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the energy, $E_t$, between them by concatenating them together and passing them through a linear layer (`W_a`) and a $\\tanh$ activation function. \n",
    "\n",
    "$$E_t = \\tanh(W_a([S_{t-1}; H]^T))$$\n",
    "\n",
    "where $E_t$ is a **[decoder_hidden_dim, src_len]** tensor.\n",
    "\n",
    "**Please paste the line(s) that calculate $E_t$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, we want convert $E_t$ to be a vector of **[src_len]** size for **each example** in the batch as the attention should be over the length of the source sentence. This is achieved by multiplying the `energy` by a **[1, decoder_hidden_dim]** tensor, $v_a$.\n",
    "\n",
    "$$\\hat{a}_t = v_a E_t$$\n",
    "\n",
    "**Please paste the line(s) that calculate $\\hat{a}_t$ in a batch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a $\\text{softmax}$ layer.\n",
    "\n",
    "$$a_t = \\text{softmax}(\\hat{a_t})$$\n",
    "\n",
    "**Please paste the line(s) that calculate $a_t$ and return it to Decoder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Write code to inplement global attention with dot product/multiplicative attention function\n",
    "rubric={mechanics:1}\n",
    "\n",
    "Intead of using the **additive attention** to get attenntion score $a_t$:\n",
    "$$\\alpha_i = softmax(v_a \\tanh(W_a[S_{i-1}; H]^T))$$\n",
    "\n",
    "**We will use the *global attention with dot product alignment function* (Dot-Product/Multiplicative based attention function, that is, $\\alpha_i = softmax([s_{i-1}^T h_1,\\cdots,s_{i-1}^T h_t])$ to calculate attention score $\\alpha_i$ and follow the subsequent steps to generate translation token $\\hat{y_t}$**: \n",
    "1. initialize the `outputs` tensor is created to hold all predictions, $\\hat{Y} = \\{\\hat{y_1} ... \\hat{y_t}\\}$ where t is the maximal length of target language;\n",
    "2. the source sequence, $X = \\{x_1,..., x_t\\}$, is fed into the encoder to receive last hidden state, $h_t$, and last cell state $c^{Encoder}_t$;\n",
    "3. the initial decoder hidden state is set to be the $h_t$, and the initial decoder cell state is set to be the $c_t$. (i.e., $s_0$ = $h_t$; $c^{Decoder}_0$ = $c^{Encoder}_t$);\n",
    "4. we use a batch of `<sos>` tokens as the first `input` (i.e., $y_0$);\n",
    "5. we then decode within a loop:\n",
    "\n",
    " for i in range(1,t): t is the maximal length of target language\n",
    "    1. inserting the input token $y_i$, previous hidden state, $s_{i-1}$, and previous cell state, $c^{Decoder}_{i-1}$, into the Decoder;\n",
    "    2. use **`attention_function()`** to calculate attention vector based on $h_1,\\dots,h_t$ (all encoder hidden states stacked up is $H$) and $s_{i-1}$;\n",
    "        3. use this attention vector to create a weighted context vector, $c_i$, denoted by `weighted`, which is a weighted sum of the encoder hidden states, $H$, using $\\alpha_t$ as the weights (i.e., $c_i = \\alpha_t^T H$);\n",
    "    4. concatenate the embedding corresponding to the current decoder input token with with weighted context vector $c_i$, and pass this concatination through the decoder RNN, to get a new hidden state $s_{i}$ that shape is `[batch, decoder hidden dimension]`.\n",
    "    5. pass $s_{i}$ through the linear layer, $f_output$, to make a prediction of the next word in the target sentence, $\\hat{y}_{t+1}$.\n",
    "    6. decide if use **teacher forcing** or not, setting the next input as appropriate.\n",
    "\n",
    "\n",
    "where **`attention_function()`** is based on **dot product attention**:\n",
    "$\\alpha_i = softmax([s_{i-1}^T h_1,\\cdots,s_{i-1}^T h_t])$\n",
    "\n",
    "\n",
    "**The pseudo code for computing attention vector:**\n",
    "\n",
    "```\n",
    "class Decoder(nn.Module):\n",
    "        INPUT: \n",
    "        current Decoder hidden state (s_{i-1}), decoder_output: [batch size, dec hid dim]\n",
    "        all hidden state of last layer of Encoder (H), encoder_outputs: [src len, batch size, enc hid dim]\n",
    "        OUTPUT: \n",
    "        attention_vector (a_t), attention_vector: (batch_size, src_len)\n",
    "        ------------------------------------------------------------------------------------------\n",
    "        # For-loop version: \n",
    "        attention_vector = Variable(torch.zeros(batch_size, ecoder_src_len))\n",
    "\n",
    "        # For every batch, every time step of encoder's hidden state, calculate attention score.\n",
    "        for b in range(batch_size):\n",
    "            for t in range(max_src_len):\n",
    "                # Luong et al. (2015) equation(8) -- dot form content-based attention:\n",
    "                attention_vector[b,t] = decoder_output[b] **dot product** encoder_outputs[t,b]\n",
    "                \n",
    "        ------------------------------------------------------------------------------------------\n",
    "        # Vectorized version:\n",
    "\n",
    "        1. attention_vector =  \n",
    "           (batch_size, seq_len=1, hidden_size) **batch matrix-matrix product** (batch_size, hidden_size, max_src_len) = (batch_size, seq_len=1, max_src_len)\n",
    "           \n",
    "         return attention_vector\n",
    "```\n",
    "\n",
    "Equation 8 from Luong's paper is:\n",
    "<img src=\"attention_images/luong_eqn8.png\\\" title=\"equation 8 from Luong paper\" height=\"550\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction:**\n",
    "- Please paste your experiment codes to answer the corresponding question below.\n",
    "- You should train your model with the following hyper-parameters:\n",
    "```\n",
    "INPUT_DIM = 6004\n",
    "OUTPUT_DIM = 6004\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "N_LAYERS = 1\n",
    "BI_DIRECTION = True\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = XXXXX (you should figure out this hyper-parameter). \n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.3\n",
    "TEACH_FORCING_RATE = 0.5\n",
    "LEARNING_RT = 0.001\n",
    "MAX_EPOCH = 15\n",
    "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n",
    "```\n",
    "- You should use `init_weights()` function from this week tutorial to initialize model with normal distribution which `mean=0` and `std=0.01`.\n",
    "- Your seed of randomization should be 77 (i.e., manual_seed = 77). \n",
    "- You should use `nn.CrossEntropyLoss()` loss function and ignore `<pad>` tokens.\n",
    "- You should save the model to checkpoint at the end of each epoch. You also need to save your vocabularies.\n",
    "- You should use a different checkpoint directory to avoid overwriting previous models. \n",
    "- Then, you load the best checkpoint and evaluate it on TEST set. \n",
    "- You should keep your vocabularies and best checkpoints. We will use them in Exercise 3 (Error analysis). \n",
    "\n",
    "**Hints:**\n",
    "- This exercise is more related to last tutorial (i.e., week 2). \n",
    "- Although the Encoder is bi-directional LSTM, the Decoder must be a uni-directional LSTM.\n",
    "- The last hidden state of the LSTM is `h_n` of shape (num_layers * num_directions, batch, hidden_size).\n",
    "- The last cell state of the LSTM is `c_n` of shape (num_layers * num_directions, batch, hidden_size).\n",
    "- The all hidden states from the last LSTM layer is `output` of shape (seq_len, batch, num_directions * hidden_size).\n",
    "- The initialization states (i.e., $s_0$,$c_0$) of Decoder must match the dimension of Decoder. Namely, you should give a appropriate number of `DEC_HID_DIM` via analyzing the relation between tensor shapes. \n",
    "- You can use `print(XXX.shape)` to check the shape of your tensor. If the tensor shape doesn't match the desired shape of tensor, you should reshape it using `.view(), .squeeze(), .unsqueeze() or .permute() function.`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Please paste your fully training log here. Which epoch is the best?\n",
    "rubric={accuracy:2}\n",
    "You log should look like this:\n",
    "```\n",
    "Epoch: 01 | Time: 1m 25s\n",
    "\tTrain Loss: 4.293 | Train PPL:  73.188\n",
    "\t Val. Loss: 4.263 |  Val. PPL:  71.012 \n",
    "   ............\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer:**\n",
    "**My best model is trained with XX epochs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Your log goes here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Please report the cumulative BLEU-4 score on test set (i.e., `test_eng_fre.tsv`) via the corpus_bleu() function.\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Hint: You can use `inference()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here**\n",
    "\n",
    "**My best model obtains XX.XX cumulative BLEU-4 score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please paste your code for the corresponding questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 You may need to revise `class Encoder`. Pleae show your code for `class Encoder`:\n",
    "rubric={accuracy:2, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4  You may need to revise `class Decoder`. Pleae show your code for `class Decoder`:\n",
    "rubric={accuracy:4, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4a  Give your code for the `class Attention`:\n",
    "rubric={accuracy:4, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 You may need to revise `class Seq2Seq`. Pleae show your code for `class Seq2Seq`:\n",
    "rubric={accuracy:2, efficiency:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 You may need to revise the code of instantiating classes. Pleae show your instantiation code:\n",
    "rubric={accuracy:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 Please write code to visualize the attention alignment of following sentences using your best model in 2.2 and include your visualization pictures in your Lab3 directory. Your visualization pictures should be named `ex2_sentence_n.png` where $n$ is the index. Please include your code in `Lab3_exp.ipynb`.\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Une femme lit un magazine par dessus l'épaule d'une autre femme.\"\n",
    "sentence_2 = \"Un gars torse nu regardant au loin tandis que trois femmes passent devant une foule assise devant un café.\"\n",
    "sentence_3 = \"Deux groupes de baigneurs barbotent dehors.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your translation here**\n",
    "\n",
    "My translation:\n",
    "- sentence_1:\n",
    "- sentence_2:\n",
    "- sentence_3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 Please write code to visualize the attention alignment of three sentences in 2.2.7 using your best model of `seq2seq+additive attention (this week tutorial)` and include your visualization pictures in your Lab3 directory. Your visualization pictures should be named `tutorial3_sentence_n.png` where $n$ is the index. Please include your code in `Lab3_exp.ipynb`.\n",
    "rubric={accuracy:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your translation here**\n",
    "\n",
    "My translation:\n",
    "- sentence_1:\n",
    "- sentence_2:\n",
    "- sentence_3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.9 Please compare the translation of 2.2.7 and 2.2.8 and provide a error analysis. (OPTIONAL)\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Hints:\n",
    "- try to identify issues with the translation.\n",
    "- If you don’t know the two languages, you can compare against Google translation. \n",
    "- Which model is better? Why?\n",
    "- You answer should be less than 100 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have four seq2seq models: (1) basic seq2seq from week2 tutorial (`seq2seq_tutorial.ipynb`); (2) seq2seq with additive attention from week3 tutorial (`attention_tutorial.ipynb`); (3) seq2seq variant of Exercise 1; (4) seq2seq with dot product attention in Exercise 2. Please use the best models of these four models to answer the following questions. \n",
    "\n",
    "If you had problems creating any of these 4 models, just report your results on the models you were able to make work/develop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Please report the cumulative BLEU-4 score on test set (i.e., `test_eng_fre.tsv`) via the corpus_bleu() function.\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Hint: You can use `inference()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**\n",
    "- For model (1), **my best model obtains XX.XX cumulative BLEU-4 score with XX epoch(s).** \n",
    "- For model (2), **my best model obtains XX.XX cumulative BLEU-4 score with XX epoch(s).** \n",
    "- For model (3), **my best model obtains XX.XX cumulative BLEU-4 score with XX epoch(s).** \n",
    "- For model (4), **my best model obtains XX.XX cumulative BLEU-4 score with XX epoch(s).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Please evaluate any one of four models on on test set (i.e., `test_eng_fre.tsv`) and report its BLEU-1, cumulative BLEU-2, BLEU-3, and BLEU-4 scores via the corpus_bleu() function.\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Hints: \n",
    "- You can use the `inference()` function. But you will need to revise few lines of this function.\n",
    "- You may need to review the BLEU implementation in week 2 tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**\n",
    "- **I evaluate on model (X).** \n",
    "- **This model obtains XX.XX BLEU-1 score** \n",
    "- **This model obtains XX.XX cumulative BLEU-2 score** \n",
    "- **This model obtains XX.XX cumulative BLEU-3 score** \n",
    "- **This model obtains XX.XX cumulative BLEU-4 score** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Please explain the results of 3.2 briefly. \n",
    "rubric={reasoning:2}\n",
    "\n",
    "Hints: What is the relationship between BLEU-n scores? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the effects of sentence length, we create two subsets of test file: A. `long_test_eng_fre.tsv` which only includes sentence pairs that English reference is longer than 19 tokens; B. `short_test_eng_fre.tsv` which only includes sentence pairs that English reference is shorter than 9 tokens. `long_test_eng_fre.tsv` includes 67 sentence pairs.  `short_test_eng_fre.tsv` includes 85 sentence pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Please report the cumulative BLEU-4 score on long sentences of test set (i.e., `long_test_eng_fre.tsv`) via the corpus_bleu() function. \n",
    "rubric={accuracy:2}\n",
    "\n",
    "Hint: You can use `inference()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**\n",
    "\n",
    "Evaluate on `long_test_eng_fre.tsv`:\n",
    "- For model (1), **my best model obtains XX.XX cumulative BLEU-4.** \n",
    "- For model (2), **my best model obtains XX.XX cumulative BLEU-4.**\n",
    "- For model (3), **my best model obtains XX.XX cumulative BLEU-4.**\n",
    "- For model (4), **my best model obtains XX.XX cumulative BLEU-4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Please report the cumulative BLEU-4 score on short sentences of test set (i.e., `short_test_eng_fre.tsv`) via the corpus_bleu() function. \n",
    "rubric={accuracy:2}\n",
    "\n",
    "Hint: You can use `inference()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You answer goes here:**\n",
    "\n",
    "Evaluate on `short_test_eng_fre.tsv`:\n",
    "- For model (1), **my best model obtains XX.XX cumulative BLEU-4.** \n",
    "- For model (2), **my best model obtains XX.XX cumulative BLEU-4.**\n",
    "- For model (3), **my best model obtains XX.XX cumulative BLEU-4.**\n",
    "- For model (4), **my best model obtains XX.XX cumulative BLEU-4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Please compare the results of questions of 3.1-3.3. Which model does perform best? What differences between their performance? How does the length of sentence affect performance?\n",
    "rubric={reasoning:4}\n",
    "\n",
    "Hint:\n",
    "- You can review the Section 5 of [Luong et al. (2015)](https://arxiv.org/pdf/1508.04025.pdf) to answer this question.\n",
    "- You answer should be less than 100 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 Conceptual Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 BLEU\n",
    "rubric={reasoning:2}\n",
    "\n",
    "BLEU is one of the most widely used metrics for NLP, but why can't we just use accuracy to measure the success of translations? Does accuracy make sense in machine translation? \n",
    "\n",
    "Hint: Feel free to do some research to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Teacher Forcing\n",
    "rubric={reasoning:2}\n",
    "\n",
    "For training seq2seq models we often use Teacher Forcing as part of the training procedure. Identify two advantages of using this approach in training.  \n",
    "\n",
    "Hint: Feel free to do some research to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Attention bottleneck\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Learning attention functions automatically require large volumes of data especially for recurrent neural networks. Can you recommend a solution to overcome this problem? Barrett and Bingel investigate an approach to solve this limitation. Take a few minutes to SKIM the abstract and introduction and write a few sentences summarizing takeaways that you can use in practice.\n",
    "\n",
    "Barrett, M., Bingel, J., Hollenstein, N., Rei, M., & Søgaard, A. (2018, October). Sequence classification with human attention. In Proceedings of the 22nd Conference on Computational Natural Language Learning (pp. 302-312).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Global Attention Mechanisms\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Global attention mechanisms consider all the encoder hidden states when deriving the context vector while local attention mechanisms consider only a subset of the encoder hidden states when deriving the context vector. [Luong et al. 2015](https://arxiv.org/pdf/1508.04025.pdf) proposed **three global attention mechanisms**. In the tutorial, we looked at (terminologies are borrowed from Luongs's paper):\n",
    "* Dot: $e_{ij} = s_{i-1}^Th_j \\in \\mathcal{R}$\n",
    "* Concat: $e_{ij} = v_a tanh( W_a [s_{i-1};h_j;]) \\in \\mathcal{R}$ where $W_a \\in \\mathcal{R}^{h\\times 2h}$ and $v_a \\in \\mathcal{R}^{1\\times h}$\n",
    "\n",
    "Can you find out the third global attention mechanism by going over the paper (especially Section 3.1) and write it down in the same format as above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
