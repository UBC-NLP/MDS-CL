{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1 - Machine Translation - MDS Computational Linguistics\n",
    "\n",
    "### Assignment Topics\n",
    "- Phrase Based Machine Translation\n",
    "- Multilingual Word Embeddings\n",
    "- MT datasets\n",
    "\n",
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.2.0) \n",
    "- Jupyter (latest)\n",
    "\n",
    "- GIZA++ Needs:\n",
    "    - Perl\n",
    "    - OSX/Linux (recommended) or a Cygwin Terminal\n",
    "    \n",
    "If you are installing GIZA++ on Cygwin, make sure you have Perl, make, and GCC/G++ installed when you install Cygwin (default installation does not include these)\n",
    "\n",
    "### Submission Info.\n",
    "- Due Date: February 29, 2020, 18:00:00 (Vancouver time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: GIZA++ Warm Up\n",
    "\n",
    "For the following \"warm up\" questions, check that you are understanding GIZA++'s outputs.\n",
    "\n",
    "### 1.1 Interpretting GIZA++ results\n",
    "rubric={reasoning:2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these three sentences, which one does GIZA++ handle \"best\"? Explain how you should measure \"best\" with GIZA++\n",
    "\n",
    "###### A. Sentence pair (28) source length 7 target length 8 alignment score : 1.13908e-07\n",
    "- It is the case of Alexander Nikitin . =\n",
    "- NULL ({ }) Es ({ 1 2 }) el ({ 3 }) caso ({ 4 }) de ({ 5 }) Alexander ({ 6 }) Nikitin ({ 7 }) . ({ 8 }) \n",
    "\n",
    "###### B. Sentence pair (122) source length 6 target length 7 alignment score : 7.36437e-21\n",
    "- You did not call me either . =\n",
    "- NULL ({ }) Tampoco ({ 3 }) me ({ 5 }) ha ({ 2 }) nombrado ({ 4 6 }) usted ({ 1 }) . ({ 7 }) \n",
    "\n",
    "###### C. Sentence pair (115) source length 4 target length 7 alignment score : 8.73259e-12\n",
    "- There is no room for amendments . =\n",
    "- NULL ({ 2 5 }) No ({ 1 }) caben ({ 3 4 }) modificaciones ({ 6 }) . ({ 7 }) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 GIZA++ vocab \n",
    "rubric={reasoning:1}\n",
    "\n",
    "What do the two numbers represent in this sample GIZA++ vocab entry? (see europarl-es-en/giza_output/en-es.trn.trg.vcb from the tutorial)\n",
    "\n",
    "```\n",
    "45 producido 391\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3a GIZA++ Translation Tables\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Below is a (partial) GIZA++ translation table for one of the words in the corpus. What is the word index of the target language most likely be the translation of source language? [Note this should look bad on GitHub but fine in a jupyter notebook]\n",
    "\n",
    "*Hint:You should understand what the three numbers of each row represent.* \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6 5 0.344281\n",
    "6 6 0.0051642\n",
    "6 70 0.360418\n",
    "6 164 2.0722e-07\n",
    "6 242 0.00264185\n",
    "6 269 1.49345e-05\n",
    "6 350 1.24741e-07\n",
    "6 408 0.00296726\n",
    "6 422 0.00269407\n",
    "6 433 9.45562e-05\n",
    "6 450 0.00538036\n",
    "6 452 0.00269633\n",
    "6 492 0.00272651\n",
    "6 516 9.83587e-06\n",
    "6 613 0.0026897\n",
    "6 747 0.00478991\n",
    "6 762 0.0162501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3b GIZA++ Translation Tables\n",
    "rubric={reasoning:1}\n",
    "\n",
    "In the above translation table, is the vocab index (6) coming from the source vocab or target vocab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Build a French-English/English-French Dictionary \n",
    "**(May work together as group of 2 for 2.1 of this exercise)**\n",
    "Using GIZA++ we would like you to build a French-English/English-French dictionary. Because of the installation requirements for GIZA++ it may be beneficial to **partner with someone** to generate the GIZA++ files, otherwise try doing this alone to understand the process of getting GIZA++ to run.\n",
    "\n",
    "First, Download the En/Fr parallel corpus here: http://www.statmt.org/europarl/ and follow the procedure in the tutorial to create the aligned output from GIZA++.  Decrease the size of the file to 200,000 sentences to speed up the training time using the following command (where filename and newfilename are your original and truncated corpus respectively):\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "head -200000 filename > newfile_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Check your output (Partner OK)\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Were you able to get it to align appropriately? Copy the first three alignments out of your *.VA3.final file  \n",
    "\n",
    "Please indicate who your partner was for getting GIZA++ to run as well.\n",
    "\n",
    "[Make sure both partners have copies of all the output files in order to do the remainder of the exercise.]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Partner name:\n",
    "\n",
    "#Paste output here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a dictionary\n",
    "rubric={quality:15}\n",
    "\n",
    "Using the output files from 2.1, create a program to build a bilingual French-English/English-French dictionary, the dictionary should be a function that takes in a word and a language argument and returns the most likely word based on the GIZA++ alignment. Comment your code.\n",
    "\n",
    "*Hint: You need to use source and target vocabularies and translation table.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myDictionary(keyword, language):\n",
    "# your code goes here\n",
    "    return alignment_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate your function by testing the following words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myDictionary(\"vous\",language=\"french\"))\n",
    "print(myDictionary(\"Minutes\",language=\"english\"))\n",
    "print(myDictionary(\"awesome\",language=\"french\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Neural Language Alignment\n",
    "\n",
    "We compare GIZA++'s alignment with MUSE to see how purely statistical models compare with neural models.\n",
    "\n",
    "First get the English and French aligned word embeddings from https://github.com/facebookresearch/MUSE\n",
    "\n",
    "Next some libraries for graphings things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cosine Similarity\n",
    "rubric{accuracy:2}\n",
    "\n",
    "Cosine similarity is used fairly frequently in NLP.\n",
    "\n",
    "$similarity = cos(\\theta) = \\frac{A \\cdot B}{||A|| ||B||} = \\frac{\\sum_{i=1}^{d} A_iB_i}{\\sqrt{\\sum_{i=1}^{d} A^2_i}\\sqrt{\\sum_{i=1}^{d} B^2_i}}$\n",
    "\n",
    "Using the following two tensors (of a dim=3 embedding) show **by hand** how you would calculate the cosine similarity between these two vectors.\n",
    "\n",
    "A = [ 0.1010, -1.1388, -0.7991]\n",
    "\n",
    "B = [ 0.5083, -0.2255,  1.9037]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write Answer Here** (alternatively take a picture of your work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plotting Aligned Embeddings\n",
    "rubric{accuracy:2}\n",
    "\n",
    "For the following set of words: \"excessively\", \"Minutes\", \"citizens\", \"standards\", and \"disaster\" create a 2D diagram showing the words in vector space alongside their French closest 'equivalents'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Comparing MUSE to GIZA++\n",
    "rubric{reasoning:2}\n",
    "\n",
    "Based on the words that you have identified, how do the MUSE pre-trained embeddings compare with the GIZA++ mappings? Which method do you think works better in practice? What might be some drawbacks of this comparison?\n",
    "\n",
    "\n",
    "*Hint:You can perform a case-study to compare the alignment dictionary.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Goes Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: MUSE from scratch (OPTIONAL)\n",
    "\n",
    "We sort of cheated in Exercise 3 with using the pre-aligned embeddings, unfortunately these are trained on Wikipedia, and thus not a great comparison to the Europarl corpus dictionary we've made with GIZA++. We've marked this exercise as optional due to some finicky requirements for running MUSE, but we strongly suggest you try it due to how powerful it can be.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- OSX/Linux\n",
    "- https://github.com/facebookresearch/faiss (Optional but recommended)\n",
    "- CUDA capable GPU (Strongly recommended)\n",
    "\n",
    "### 4.1 Create Fastext word embeddings for Europarl (Optional)\n",
    "rubric={accuracy:5}\n",
    "\n",
    "FasText is similar to Word2Vec, but has some slight improvements (e.g. it can capture orthographic information). You can get it:\n",
    "https://github.com/facebookresearch/fastText and then follow the instructions to train an embedding model for the English and French Europarl corpuses you downloaded earlier for 2.1.\n",
    "\n",
    "Copy your training procedure below as well as give example outputs for the closest words to \"Minutes\", \"minutes\", and \"vote\" for English and \"vous\", \"intervienne\", and \"accord\" for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your training code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give example outputs for the suggested words: \"Minutes\", \"minutes\", and \"vote\" for English and \"vous\", \"intervienne\", and \"accord\" for French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Use MUSE to align the word embeddings (Optional)\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Using MUSE's unsupervised functionality, align the two language embedding spaces and find the closest French words that match the English words \"disaster\", \"vote\", and \"excessively\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Put your output here from the similarity check for the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Compare MUSE with GIZA++ (Optional)\n",
    "rubric{reasoning:5}\n",
    "\n",
    "Based on the aligned dictionaries you've made, qualitatively does there seem to be much difference between GIZA++ and MUSE? Which one appears to work better? Write a brief (2-3 sentence) comparison of both the process to make the two dictionaries and the ultimate quality of the final dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Conceptual Questions\n",
    "\n",
    "### 5.1 Data Sets\n",
    "rubric{reasoning:3}\n",
    "\n",
    "Aligned corpuses are vital when it comes to creating a Machine Translation model. We used Europarl for this assignment, but you should think about your language needs if you are planning on working on projects dealing with non-European languages or other genres of text. Find two datasets that you might be interested in using for this unit. \n",
    "\n",
    "One should be from the [Linguistics Data Consortium](https://catalog.ldc.upenn.edu/search) of which UBC is a member. To access the datasets that UBC has available please use [Abacus](https://resources.library.ubc.ca/page.php?details=abacus&id=1114)  (Recommended that you search on the LDC website, which has a better metadata search engine for the datasets, make sure you find something that has a parallel translation, and then locate the dataset on Abacus by searching for the title of it. Note UBC has many, but not all of the sets)\n",
    "\n",
    "A second source should be a free source available online:  (e.g. https://lionbridge.ai/datasets/25-best-parallel-text-datasets-for-machine-translation-training/ or something else)\n",
    "\n",
    "For these two corpuses please identify:\n",
    "\n",
    "- What language pair(s) are covered by the corpus\n",
    "- Size of the corpus\n",
    "- \"Style\" of text covered (is it formal text? news writing? email? informal social media posts?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response goes here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
