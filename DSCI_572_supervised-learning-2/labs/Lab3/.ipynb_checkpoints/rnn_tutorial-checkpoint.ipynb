{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks - Supervised Learning II - MDS Computational Linguistics\n",
    "\n",
    "### Goal of this tutorial\n",
    "- Introduce Recurrent Neural Networks (RNNs)\n",
    "- Implement RNN for sentiment analysis\n",
    "- Implement Long-Short Term Memories (LSTMs) for sentiment analysis\n",
    "- Implement Gated Recurrent Units (GRUs) for sentiment analysis\n",
    "\n",
    "### General\n",
    "- This notebook was last tested on Python 3.6.9 and PyTorch 1.2.0\n",
    "\n",
    "We would like to acknowledge the following materials which helped as a reference in preparing this tutorial:\n",
    "- https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "Recurrent Neural Networks (RNNs) are used to model sequences of arbitrary length (e.g., sequence of words in a sentence, sequence of sentences in a document, sequence of frames in a video). RNNs typically use their internal state (memory) to process sequence of inputs. At each time-step, RNNs output a prediction and hidden state, feeding its previous hidden state into each next step. RNNs are applied in a wide range of NLP applications:\n",
    "- language modeling, where RNN can condition on **all** previous words in the corpus unlike n-gram language model\n",
    "- text classification, where the states act as features (we will see sentiment analysis in this tutorial)\n",
    "- machine translation, where a RNN is used to process a sentence in source language and another RNN is used to decode the sentence in target language (we will see this in the \"Machine Translation\" course)\n",
    "- sequence labeling, where the states in RNN are used to predict a category for each item in the sequence (we might see named entity recognition in the next tutorial)\n",
    "\n",
    "Recommended reading for understanding the theory of RNNs: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing few tweets using torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us follow **torchtext** tutorial to read few tweets from the [sentiment analysis dataset](http://alt.qcri.org/semeval2016/task4/) used in the previous tutorial on feedforward neural networks. The preprocessed (tokenization, removing URLs, mentions, hashtags and so on) tweets are placed under ``data/sentiment-twitter-2016-task4`` folder in three files as ``train.tsv``, ``dev.tsv`` and ``test.tsv``.  \n",
    "\n",
    "Let us view few tweets from ``train.tsv`` using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear &lt;&lt;&lt;MENTION&gt;&gt;&gt; the newooffice for mac is g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;&lt;&lt;MENTION&gt;&gt;&gt; how about you make a system that...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i may be ignorant on this issue but should we ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thanks to &lt;&lt;&lt;MENTION&gt;&gt;&gt; i just may be switchin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i make a game as a &lt;&lt;&lt;HASHTAG&gt;&gt;&gt; universal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  dear <<<MENTION>>> the newooffice for mac is g...  2\n",
       "1  <<<MENTION>>> how about you make a system that...  2\n",
       "2  i may be ignorant on this issue but should we ...  2\n",
       "3  thanks to <<<MENTION>>> i just may be switchin...  2\n",
       "4  if i make a game as a <<<HASHTAG>>> universal ...  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/sentiment-twitter-2016-task4/train.tsv\", sep = '\\t', header=None) # the separator of tsv file is `\\t`\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick up 5 tweets from the training set and convert them to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import related packages\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "# define the white space tokenizer to get tokens\n",
    "def tokenize_en(tweet):\n",
    "    \"\"\"\n",
    "    Tokenizes English tweet from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return tweet.strip().split()\n",
    "\n",
    "# define the TorchText's fields\n",
    "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=True)\n",
    "LABEL = Field(sequential=False, unk_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the different splits (training, development and testing), we use `TabularDataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = TabularDataset.splits(\n",
    "    path=\"./data/sentiment-twitter-2016-task4\", # the root directory where the data lies\n",
    "    train='train.tsv', validation=\"dev.tsv\", test=\"test.tsv\", # file names\n",
    "    format='tsv',\n",
    "    skip_header=False, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "    fields=[('tweet', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our vocabulary to map words to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=2) # buiilds vocabulary based on all the words that occur at least twice in the training set\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the iterators for the train, validation, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    " (train, val, test), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(5,64,64),\n",
    " sort_key=lambda x: len(x.tweet), \n",
    " sort=True,\n",
    "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
    " sort_within_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a batch of five examples and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed tweets: \n",
      "0  sample: ['new', '<unk>', 'with', 'bentley', 'tomorrow']\n",
      "1  sample: ['bringing', 'the', 'bentley', 'out', 'tomorrow']\n",
      "2  sample: ['<<<mention>>>', 'make', 'david', 'beckham', 'tomorrow']\n",
      "3  sample: ['ihop', 'is', 'the', 'move', 'tomorrow']\n",
      "4  sample: ['i', 'want', 'ihop', 'tomorrow', 'morning']\n"
     ]
    }
   ],
   "source": [
    "# create a single batch and terminate the loop\n",
    "for batch in train_iter:\n",
    "    tweets = batch.tweet\n",
    "    labels = batch.label\n",
    "    break  #we use first batch as an example.\n",
    "\n",
    "# print the five examples with padding \n",
    "print(\"processed tweets: \")\n",
    "for j in range(tweets.shape[1]): # sample loop\n",
    "    tmp = []\n",
    "    for i in range(tweets.shape[0]): # token loop\n",
    "        tmp.append(TEXT.vocab.itos[tweets[i,j]])\n",
    "    print(j,\" sample:\",tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a single hidden layer RNN\n",
    "\n",
    "PyTorch has ``torch.nn.RNN`` module that implements the vanilla (Elman) RNN with *tanh* or *ReLU* non-linearity. The documentation for this module is [here](https://pytorch.org/docs/stable/nn.html#torch.nn.RNN). Let us use the sample batch of five examples created before to understand this module.\n",
    "\n",
    "In this tutorial, we will represent the input tweet using a sequence of word embeddings (for each word present in the tweet). We will use ``torch.nn.Embedding module`` to store word vectors corresponding to words in the vocabulary.\n",
    "\n",
    "Before implementing the embedding module for our usecase, let us compute the size of the word vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4875\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement the embedding module for our usecase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Embedding module containing 10 dimensional tensor for each word in the vocabulary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Note, the parameters to Embedding class below are:\n",
    "# num_embeddings (int): size of the dictionary of embeddings\n",
    "# embedding_dim (int): the size of each embedding vector\n",
    "# For more details on Embedding class, see: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/sparse.py\n",
    "embedding = nn.Embedding(VOCAB_SIZE, 10, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now feed the tensors of our sample batch to the embedding module and extract the sequence of word embeddings for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word ids:  tensor([[  49, 1273,    4,  191,    6],\n",
      "        [   0,    2,   82,   14,   76],\n",
      "        [  18,  215,   73,    2,  191],\n",
      "        [ 215,   48,  145,  598,   21],\n",
      "        [  21,   21,   21,   21,  136]])\n",
      "tweet input word embeddings size:  torch.Size([5, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "# print tensor containing word ids for our batch\n",
    "print(\"word ids: \", tweets.data)\n",
    "\n",
    "# feed the \"word ids\" tensor to the embedding module\n",
    "tweet_input_embeddings = embedding(tweets)\n",
    "\n",
    "# print the dimensions of the tweet_embeddings\n",
    "print(\"tweet input word embeddings size: \", tweet_input_embeddings.size()) \n",
    "# first dimension - number of examples (5)\n",
    "# second dimension - number of words in that single example (5)\n",
    "# third dimension - number of features for a word (10) (or word embedding size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define the RNN module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the RNN module\n",
    "\"\"\"\n",
    "# first input - number of features in x (10, size of the word embedding)\n",
    "# second input - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "# third input - number of recurrent layers (1)\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=1) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN module takes two inputs: *the initial hidden state for each element in the batch* (t=0) and the *input features* (``tweet_input_embeddings`` in our case).\n",
    "\n",
    "Let us construct the initial hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hidden layer at time-step 0 (h_0)\n",
    "\"\"\"\n",
    "# first dimension - number of RNN layers (1)\n",
    "# second dimension - number of words in the single example (5)\n",
    "# third dimension - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "h0 = torch.randn(1, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us feed both the hidden representation constructed above and tweet embeddings to our RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the RNN model\n",
    "\"\"\"\n",
    "output, hn = rnn(tweet_input_embeddings, h0) # h0 is optional input, defaults to tensor of 0's of apprpriate size (num_layers, batch, hidden_size) when not provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``output`` tensor contains the output features $h_t$ from the last layer of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of RNN)\n",
    "print(\"output size: \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``hn`` is a tensor of shape (num_layers, batch, hidden_size) containing the hidden state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([1, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take the output representation for a tweet after processing the last token (t=seq_len or last timestep) and call the resulting representation as the tweet representation that \"summarizes\" the information present in the tweet. This tweet representation can further be used for a useful task like tweet classification (we will try out sentiment analysis later in this tutorial) by adding a classification module on top of the tweet representation.\n",
    "\n",
    "Let us compute the final tweet representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet output embeddings size:  torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "tweet_output_embeddings = output[-1,:,:] # -1 fetches the embeddings from the last timestep\n",
    "print(\"tweet output embeddings size: \", tweet_output_embeddings.size())\n",
    "# first dimension - number of tweets in the batch (5)\n",
    "# second dimension - number of features in hidden state h_t (20, size of the hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayered RNN\n",
    "\n",
    "For some applications, we may need more than one hidden layer for RNN to model the information flow. Adding more layers requires fews changes.\n",
    "\n",
    "Firstly, we change the ``num_layers`` argument to reflect the number of layers we want during the RNN module definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define a 2 layered RNN module\n",
    "\"\"\"\n",
    "# first input - number of features in x (10, size of the word embedding)\n",
    "# second input - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "# third input - number of recurrent layers (2)\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to single layered RNN, Multilayered RNN module takes two inputs: the initial hidden state for each element in the batch (t=0) and the input features (tweet_input_embeddings in our case).\n",
    "\n",
    "Let us construct the new initial hidden state for a 2 layered RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hidden layer at time-step 0 (h_0)\n",
    "\"\"\"\n",
    "# first dimension - number of RNN layers (2)\n",
    "# second dimension - number of words in the single example (5)\n",
    "# third dimension - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "h0 = torch.randn(2, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us feed both the hidden representation constructed above and tweet embeddings to our RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the RNN model\n",
    "\"\"\"\n",
    "output, hn = rnn(tweet_input_embeddings, h0) # h0 is optional input, defaults to tensor of 0's when not provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``output`` tensor contains the output features $h_t$ from the last layer of the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of RNN)\n",
    "print(\"output size: \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``hn`` is a tensor of shape (num_layers, batch, hidden_size) containing the hidden state for t = seq_len for a 2 layered RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the final tweet representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet output embeddings size:  torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "tweet_output_embeddings = output[-1,:,:] # -1 fetches the embeddings from the last timestep\n",
    "print(\"tweet output embeddings size: \", tweet_output_embeddings.size())\n",
    "# first dimension - number of tweets in the batch (5)\n",
    "# second dimension - number of features in hidden state h_t (20, size of the hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for Sentiment Analysis\n",
    "\n",
    "In this section we will implement RNN for classifying the sentiment of the tweet (same task used in our previous feedforward neural networks tutorial).\n",
    "\n",
    "We will pick up most of the functions from our feedforward neural networks code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# set the seed\n",
    "manual_seed = 123\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "  torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "# hyperparameters\n",
    "MAX_EPOCHS = 5\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_CLASSES = 3\n",
    "EMBEDDING_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the full RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create a model for RNN\n",
    "\"\"\"\n",
    "class RNNmodel(nn.Module):\n",
    "  \n",
    "  def __init__(self, embedding_size, vocab_size, output_size, hidden_size, num_layers):\n",
    "    # In the constructor we define the layers for our model\n",
    "    super(RNNmodel, self).__init__()\n",
    "    # word embedding lookup table\n",
    "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size, sparse=True)\n",
    "    # core RNN module\n",
    "    self.rnn_layer = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) \n",
    "    # activation function\n",
    "    self.activation_fn = nn.ReLU()\n",
    "    # classification related modules\n",
    "    self.linear_layer = nn.Linear(hidden_size, output_size) \n",
    "    self.softmax_layer = nn.LogSoftmax(dim=0)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # In the forward function we define the forward propagation logic\n",
    "    out = self.embedding(x)\n",
    "    out, _ = self.rnn_layer(out) # since we are not feeding h_0 explicitly, h_0 will be initialized to zeros by default\n",
    "    # classify based on the hidden representation after RNN processes the last token\n",
    "    out = out[-1]\n",
    "    out = self.activation_fn(out)\n",
    "    out = self.linear_layer(out)\n",
    "    out = self.softmax_layer(out) # accepts 2D or more dimensional inputs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional hyperparameters for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters of RNN\n",
    "HIDDEN_SIZE = 20\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of the pipeline looks similar to our feedforward neural networks code (except that we are using **torchtext** instead of **DataLoader**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logic \n",
    "def train(loader):\n",
    "  total_loss = 0.0\n",
    "  # iterate throught the data loader\n",
    "  num_batches = 0\n",
    "  for batch in loader:\n",
    "    # load the current batch\n",
    "    batch_input, batch_output = batch.tweet, batch.label\n",
    "    \n",
    "    # forward propagation\n",
    "    # pass the data through the model\n",
    "    model_outputs = model(batch_input)\n",
    "    # compute the loss\n",
    "    cur_loss = criterion(model_outputs, batch_output)\n",
    "    total_loss += cur_loss.item()\n",
    "    \n",
    "    # backward propagation (compute the gradients and update the model)\n",
    "    # clear the buffer\n",
    "    optimizer.zero_grad()\n",
    "    # compute the gradients\n",
    "    cur_loss.backward()\n",
    "    # update the weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    num_batches += 1\n",
    "  return total_loss/num_batches\n",
    "\n",
    "# evaluation logic based on classification accuracy\n",
    "def evaluate(loader):\n",
    "  accuracy, num_examples = 0.0, 0\n",
    "  with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
    "    for batch in loader:\n",
    "      # load the current batch\n",
    "      batch_input, batch_output = batch.tweet, batch.label\n",
    "      # forward propagation\n",
    "      # pass the data through the model\n",
    "      model_outputs = model(batch_input)\n",
    "      # identify the predicted class for each example in the batch\n",
    "      _, predicted = torch.max(model_outputs.data, 1)\n",
    "      # compare with batch_output (gold labels) to compute accuracy\n",
    "      accuracy += (predicted == batch_output).sum().item()\n",
    "      num_examples += batch_output.size(0)\n",
    "  return accuracy/num_examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = RNNmodel(EMBEDDING_SIZE, VOCAB_SIZE, NUM_CLASSES, HIDDEN_SIZE, NUM_LAYERS) \n",
    "model.to(device)\n",
    "# define the loss function (last node of the graph)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.6099, Training Accuracy: 0.3905, Validation Accuracy: 0.3537\n",
      "Epoch [2/5], Loss: 1.6066, Training Accuracy: 0.3997, Validation Accuracy: 0.3542\n",
      "Epoch [3/5], Loss: 1.6044, Training Accuracy: 0.4045, Validation Accuracy: 0.3677\n",
      "Epoch [4/5], Loss: 1.6021, Training Accuracy: 0.3992, Validation Accuracy: 0.3512\n",
      "Epoch [5/5], Loss: 1.6000, Training Accuracy: 0.4097, Validation Accuracy: 0.3592\n"
     ]
    }
   ],
   "source": [
    "# create an instance of SGD with required hyperparameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# start the training\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "  # train the model for one pass over the data\n",
    "  train_loss = train(train_iter)  \n",
    "  # compute the training accuracy\n",
    "  train_acc = evaluate(train_iter)\n",
    "  # compute the validation accuracy\n",
    "  val_acc = evaluate(val_iter)\n",
    "  # print the loss for every epoch\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}, Training Accuracy: {:.4f}, Validation Accuracy: {:.4f}'.format(epoch+1, MAX_EPOCHS, train_loss, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUs\n",
    "\n",
    "Gated Recurrent Units (GRUs) are a variant of RNNs that use more complex units for activation. They are created to have more persistent memory thereby making them easier for RNNs to capture long-term dependencies. To learn the theory behind GRUs, we recommend: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf \n",
    "\n",
    "GRU is defined by ``torch.nn.GRU`` module and its documentation can be fetched [here](https://pytorch.org/docs/stable/nn.html#torch.nn.GRU). Now let us define the GRU module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the GRU module\n",
    "\"\"\"\n",
    "# first input - number of features in x (10, size of the word embedding)\n",
    "# second input - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "# third input - number of recurrent layers (2)\n",
    "gru_rnn = nn.GRU(input_size=10, hidden_size=20, num_layers=2) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to RNN, GRU module takes two inputs: *the initial hidden state for each element in the batch* (t=0) and the *input features* (``tweet_input_embeddings`` in our case).\n",
    "\n",
    "Let us feed both the initial hidden state and tweet embeddings to our GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the GRU model\n",
    "\"\"\"\n",
    "output, hn = gru_rnn(tweet_input_embeddings, h0) # h0 is optional input, defaults to tensor of 0's when not provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``output`` tensor contqains the output features $h_t$ from the last layer of the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of GRU)\n",
    "print(\"output size: \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``hn`` is a tensor of shape (num_layers, batch, hidden_size) containing the hidden state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to RNN, you can compute the final tweet representation (representation from last hidden state for each tweet) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet output embeddings size:  torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "tweet_output_embeddings = output[-1,:,:] # -1 fetches the embeddings from the last timestep\n",
    "print(\"tweet output embeddings size: \", tweet_output_embeddings.size())\n",
    "# first dimension - number of tweets in the batch (5)\n",
    "# second dimension - number of features in hidden state h_t (20, size of the hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs\n",
    "\n",
    "Long short-term memory (LSTMs) are a variant of RNNs that use more complex units for activation. Similar to the spirit of GRU, they are created to have more persistent memory thereby making them easier for RNNs to capture long-term dependencies. To learn the theory behind GRUs, we recommend: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf \n",
    "\n",
    "LSTM is defined by ``torch.nn.LSTM`` module and its documentation can be fetched [here](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM). Now let us define the LSTM module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the LSTM module\n",
    "\"\"\"\n",
    "# first input - number of features in x (10, size of the word embedding)\n",
    "# second input - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "# third input - number of recurrent layers (2)\n",
    "lstm_rnn = nn.LSTM(input_size=10, hidden_size=20, num_layers=2) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike RNN and GRU, LSTM module takes three inputs: the initial hidden state for each element in the batch (t=0), the input features (tweet_input_embeddings in our case) and initial cell state for each element in the batch.\n",
    "\n",
    "Let us construct the initial cell state (this construction is similar to that of initial hidden state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cell state at time-step 0 (h_0)\n",
    "\"\"\"\n",
    "# first dimension - number of LSTM layers (2)\n",
    "# second dimension - number of words in the single example (5)\n",
    "# third dimension - number of features in hidden state h_t (20, size of the hidden layer)\n",
    "c0 = torch.randn(2, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us feed the initial hidden state, initial cell state and tweet embeddings to our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the LSTM model\n",
    "\"\"\"\n",
    "output, (hn, cn) = lstm_rnn(tweet_input_embeddings, (h0, c0)) # h0 and c0 is optional input, defaults to tensor of 0's when not provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``output`` tensor contains the output features $h_t$ from the last layer of the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of LSTM)\n",
    "print(\"output size: \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``hn`` is a tensor of shape (num_layers, batch, hidden_size) containing the hidden state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cn`` is a tensor of shape (num_layers, batch, hidden_size) containing the cell state for t = seq_len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last cell state size:  torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "# c_n = num_layers, batch, hidden_size (cell state for t=seq_len or cell state at last timestep)\n",
    "print(\"last cell state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to RNN and GRU, you can compute the final tweet representation (representation from last hidden state for each tweet) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet output embeddings size:  torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "tweet_output_embeddings = output[-1,:,:] # -1 fetches the embeddings from the last timestep\n",
    "print(\"tweet output embeddings size: \", tweet_output_embeddings.size())\n",
    "# first dimension - number of tweets in the batch (5)\n",
    "# second dimension - number of features in hidden state h_t (20, size of the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ctrl_transformers)",
   "language": "python",
   "name": "ctrl_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
