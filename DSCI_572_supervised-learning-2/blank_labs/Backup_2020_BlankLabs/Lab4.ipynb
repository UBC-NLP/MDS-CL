{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4 - Supervised Learning II - MDS Computational Linguistics\n",
    "\n",
    "### Assignment Topics\n",
    "- Train a deep learning system for real-world task\n",
    "- Recurrent Neural Networks\n",
    "- Long Short-Term \n",
    "- Regularization\n",
    "- Gradient-based optimization\n",
    "- Very-short answer questions\n",
    "\n",
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.2.0) \n",
    "- Jupyter (latest)\n",
    "\n",
    "### Submission Info.\n",
    "- Due Date: February 8, 2020, 18:00:00 (Vancouver time)\n",
    "\n",
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 Application Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Yelp review rating prediction \n",
    "rubric={accuracy:40}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is a competition of real-world application. \n",
    "Millions of people share a great number of reviews about business on [Yelp.com](https://www.yelp.com/) and Yelp mobile app everyday. These reviews and ratings help other users to make a choice. We used [Yelp APIs (application programming interface)](https://www.yelp.ca/developers) to collect over 35,000 reviews of 1,000 restaurants in New York City. We split this dataset into 90\\% TRAIN set (28,000 reviews), 10\\% DEV set (3,500 reviews), and 10\\% TEST set (3,500 reviews). Each review has text review content and a corresponding label (i.e., 5-level rating star). This table shows the class ditribution of TRAIN and DEV sets.\n",
    "\n",
    "|    Rating      |     |    # of reviews  |\n",
    "|--------|-------------------|-----|\n",
    "|| Train             | Dev |\n",
    "| 1star      | 5,619              | 683 |\n",
    "| 2star      | 5,616              | 677 |\n",
    "| 3star      | 5,583              | 713 |\n",
    "| 4star      | 5,532              | 733 |\n",
    "| 5star      | 5,650              | 694 |\n",
    "\n",
    "\n",
    "In directory `./data/yelp_review/`, we provide the `TRAIN` and `DEV` sets with the corresponding labels for your system development. \n",
    "Please use the TRAIN and DEV sets to develop a classification system for this task. You can use any model of this course (e.g., linear regression, feed-forward neural network, RNN, GRUs, LSTM). We also provide `TEST` which only contain text content of review for final evaluation. You will use your best trained model to predict the labels of **`TEST` reviews** and submit your predictions. \n",
    "\n",
    "**The performance of your submitted systems will be evaluated on predictions of rating labels for reviews in TEST set. Macro Averaged F-score will be the evaluation metric.** \n",
    "\n",
    "Your mark of this Exercise = 40 * ( $1 - (F1_{max} - F1_i) ) $ where $F1_{max}$ is the highest test F1 score achieved across the class and $F1_i$ is the test F1 score you achieved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Development Instruction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data and preprocessing: Use `torchtext` load and pre-process dataset. Prepare the batch Iterators**\n",
    "\n",
    "Hints: You should select a tokenizer for your system (e.g., SpaCy English model, whitespace tokenizer, NLTK word tokenizer). \n",
    "\n",
    "**2. Model selection and hyper-parameter tuning. You need to select the architecture you want to use. You may need to search the optimal hyper-parameter set to improve your model performance.**\n",
    "\n",
    "Hints: You can use the DEV set to estimate your model performance. \n",
    "\n",
    "There are many possible strategies you could take to improve performance:   \n",
    "\n",
    "a. Changing vocabulary size, batch size. Using TF-IDF features or pre-training word embedding model as your embedding weights (e.g., [google news word2vec](https://code.google.com/archive/p/word2vec/), [GloVe](https://nlp.stanford.edu/projects/glove/), [ELMo](https://allennlp.org/elmo)).\n",
    "\n",
    "Hint: In our tutorial, we use the embedding layer with randomly initialized weights. If you initialize your embedding layer with word embedding weights from a pre-trained word embedding model from the ones listed above, you may get improvements.\n",
    "\n",
    "b. Changing model, such as linear regression, feed-forward neural network, RNN, GRUs, LSTM.\n",
    "\n",
    "c. Changing neural network structure, such as changing hidden dimension size, number of layers, dropout rate, activation function.\n",
    "\n",
    "d. Changing training procedure, such as number of epochs, learning rate, adding regulization and momentum (or RMSProp, or Adam).\n",
    "\n",
    "e. You may find some novel ideas in the state-of-the-art NLP systems [here](http://nlpprogress.com/english/sentiment_analysis.html).\n",
    "\n",
    "Hint: Due to the high requirement of computational resource, we suggest you to run your experiments on [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true). Please read `Colab instructions` for more information of Colab\n",
    "\n",
    "**3. When you get your best model on DEV set, you will use this model to predict the labels of `TEST set` and submit your prediction.**\n",
    "\n",
    "**4. For predication submission, please read `submission instruction`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab Instruction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true) will allow you to train your model on a GPU. \n",
    "\n",
    "You can follow the steps to use Colab:\n",
    "\n",
    "1. We provide a new notebook `(lab4_colab.ipynb)` for your experiments on Colab. You should develop your system on `lab4_colab.ipynb` instead of current jupyter notebook. \n",
    "2. Go to [Google colab](https://colab.research.google.com).\n",
    "3. Create an account or login your account.\n",
    "4. Select \"UPLOAD\" and upload `lab4_colab.ipynb`, again please don't upload current notebook (Lab4.ipynb).\n",
    "5. Set the hardware: \n",
    "**Go to the navigation bar, click Runtime --> Change runtime type --> Hardware accelerator --> Select GPU.**\n",
    "\n",
    "6. You don't need to install any packages. Google prepared everything for you.\n",
    "7. You can find all your generations in `Files`. You can download your notebook and files.\n",
    "\n",
    "Suggestion: \n",
    "1. You can download the notebook from Colab and overwrite your local version of **`lab4_colab.ipynb`**. \n",
    "2. If you train your model on GPU, please make sure your model, input and loss is sent to GPU using XXX.to(device) where device is `cuda`. \n",
    "3. If you want to send the GPU varibles to CPU, please use XXX.cpu() to detach from GPU. You can find more related information [here](https://pytorch.org/docs/stable/notes/cuda.html). \n",
    "\n",
    "``Warning``: Running on CPU will be slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Instrcution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In directory `./data/yelp_review/`,  `EXAMPLE_GOLD.txt` and `EXAMPLE_PRED.txt` are examples of gold and prediction files which can be used with the ``Scorer.py`` provided (description below). Your sumbission should have excactly the same structure as **`EXAMPLE_PRED.txt`** (i.e., each line contains one predication label without header of the column.) This is important.\n",
    "\n",
    "2. `./data/yelp_review/Scorer.py`\n",
    "\n",
    "The scoring script (Scorer.py) is provided at the root directory of the released data. `Scorer.py` is a python script that will take in two text files containing true labels and predicted labels and will output accuracy, F1 score, precision and recall. (Note that the evaluation metric is F1 score).  The scoring script is used for evaluating your TEST prediction.\n",
    "\n",
    "Please make sure to have `sklearn library` installed.\n",
    "```\n",
    "Usage of the scorer:\n",
    "\n",
    "    python3 Scorer.py  <gold-file> <pred-file>\n",
    "\n",
    "In the dataset directory, there are example\n",
    "gold and prediction files. If they are used with the scorer,\n",
    "they should produce the following results:\n",
    "\n",
    "python3 Scorer.py EXAMPLE_GOLD.txt EXAMPLE_PRED.txt\n",
    "\n",
    "OVERALL SCORES:\n",
    "MACRO AVERAGE PRECISION SCORE: 20.97 %\n",
    "MACRO AVERAGE RECALL SCORE: 20.97 %\n",
    "MACRO AVERAGE F1 SCORE: 20.97 %\n",
    "OVERALL ACCURACY: 20.97 %\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "1. Your submission must has **same** structure as `EXAMPLE_PRED.txt`. \n",
    "\n",
    "\n",
    "2. The predication label must be the **original label format** (`i.e., '1star', '2star', '3star', '4star', or '5star'`).\n",
    "\n",
    "Hint: You may try to geneate a synthetic file to test your code. \n",
    "\n",
    "\n",
    "3. Put your prediction txt file in this lab directory. The prediction txt file should be named with `<yourfirstname>_<yourlastname>_PRED.txt`. We will use ``Scorer.py`` to evaluate your submission.\n",
    "\n",
    "Hint: We provide a funtion `out_prediction` to help you generate the submission file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_prediction(first_name, last_name, prediction_list):\n",
    "    \"\"\"\n",
    "    out_prediction takes three input varibles: first_name, last_name, prediction_list\n",
    "    <first_name>, string, your first name, e.g., Tom\n",
    "    <last_name>, string, your last name, e.g., Smith\n",
    "    <prediction_list>, list of string which includes all your predications of TEST samples\n",
    "                        e.g., ['1star','5star','3star']\n",
    "                        \n",
    "    Generate a file is named with <yourfirstname>_<yourlastname>_PRED.txt in current directory\n",
    "    \"\"\"\n",
    "    output_file = open(\"{}_{}_PRED.txt\".format(first_name,last_name),'w')\n",
    "    for item in prediction_list:\n",
    "        output_file.write(item+\"\\n\")\n",
    "    output_file.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A example of using `out_prediction` funtion. You can find a file `Tom_Smith_PRED.txt` in your diretory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prediction(\"Tom\", \"Smith\", ['1star','5star','3star'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Please clearly describe the system you submitted in 1.1 (i.e., your best model) within 300 words.\n",
    "rubric={mechanics:5,resoning:5}\n",
    "\n",
    "Hints: \n",
    "1. Describe all the hyper-parameters of your submitted system. You may follow the structure of Development Instruction. \n",
    "2. List the strategies you attempted. What strategies did work? What did not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Please orgnize your code in `lab4_colab.ipynb` and only keep the code that you used to train your submitted system in 1.1. Submit `lab4_colab.ipynb`.\n",
    "rubric={mechanics:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 Short Answer Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What are the differences between parameter and hypyer-parameter?\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Hint: Your answer should be a maximum of 2-3 sentences. Short answers are just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute the gradient $\\nabla f(x)$ of each of the following functions. You don't need to show your work. (OPTIONAL QUESTION)\n",
    "\n",
    "rubric={accuracy:4}\n",
    "\n",
    "The notation for the gradient of a function $f$ is $\\nabla f(x)$. \n",
    "\n",
    "The input $x$ of function $f$ may be a vector, so the gradient of this function is also a vector.\n",
    "\n",
    "$x\\in \\mathbb{R}^n$ denotes the dimension of input $x$ (i.e., $x$ include $n$ elements).\n",
    "\n",
    "$\\exp(x)$ is exponential funtion, i.e., $e^x$.\n",
    "\n",
    "1. $f_1(x) = \\tanh(x_1x_2)$ where $x\\in \\mathbb{R}^2$;\n",
    "2. $f_2(x) = Sigmoid(x_1+x_2)$ where $x\\in \\mathbb{R}^2$;\n",
    "3. $f_3(x) = \\exp(x_1+x_2x_3)$ where $x\\in \\mathbb{R}^3$;\n",
    "4. $f_4(x) = \\exp(x_1 + x_2^3)$ where $x \\in \\mathbb{R}^4$\n",
    "\n",
    "Hint: \n",
    "You can find some examples of multivarible derivative in file `gradient_examples.pdf`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 What is the “gradient descent” ?\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 What is the difference between `gradient descent` and `SGD`?\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 What is the “vanishing gradient” problem with neural networks based on `Sigmoid` non-linearities?\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Why do we need regularization? What are the differences between `L1-regularization` and `L2-regularization`?\n",
    "rubric={reasoning:3}\n",
    "\n",
    "Hint: A short answer is just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 How many output does `LSTM layer of torch.nn` return? What does each of them represent? \n",
    "rubric={reasoning:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Please describe the size of each of the following tensors and the meaning of each dimension. \n",
    "rubric={accuracy:6,reasoning:6}\n",
    "\n",
    "For example, \n",
    "\n",
    "**Question 0.**\n",
    "\n",
    "If we pass a tensor with size of [32, 22] (batch size, sequence length) to a Embedding layer which is defined as (Embedding layer): Embedding(5002, 300), what size is the output? \n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The size of the output is [32, 22, 300] (batch size, sequence length, embedding dimension)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If we pass a tensor with size of `[32, 64] (batch size, sequence length)` to a Embedding layer which is defined as `(Embedding layer): Embedding(10004, 500)`, what size is the output?\n",
    "\n",
    "\n",
    "2. If we pass a tensor with size of `[32, 50] (batch size, input dimension)` to a Linear layer which is defined as  `(Linear layer): Linear(in_features=50, out_features=128`, bias=True), what size is the output?\n",
    "\n",
    "\n",
    "3. If we pass a tensor with size of `[32, 64] (batch size, hidden dimension)` to a Softmax layer which is defined as  `(softmax layer): LogSoftmax()`, what size is the output?\n",
    "\n",
    "\n",
    "4. If we pass a tensor with size of `[32, 64, 300] (sequence length, batch size`, embedding dimension) to a LSTM layer which is defined as `(LSTM layer): LSTM(300, 500, num_layers=2)`, what size is the first output returned?\n",
    "\n",
    "\n",
    "5. If we pass a tensor with size of `[32, 64, 300] (sequence length, batch size, embedding dimension)` to a LSTM layer which is defined as `(LSTM layer): LSTM(300, 500, num_layers=2, bidirectional=True)`, what size is the second output returned?\n",
    "\n",
    "\n",
    "6. If we pass a tensor with size of `[32, 64] (batch size, hidden dimension)` to a dropout layer which is defined as `(Dropout layer): Dropout(p=0.5, inplace=False)`, what size is the output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
