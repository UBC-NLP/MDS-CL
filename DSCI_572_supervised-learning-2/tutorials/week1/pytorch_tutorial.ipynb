{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch - Supervised Learning II - MDS Computational Linguistics\n",
    "\n",
    "### Goal of this tutorial\n",
    "- Introduce PyTorch, the tool for scientific computing\n",
    "- Learn the basic PyTorch concepts and modules such as tensors, computational graphs, automatic differentiation, affine transformation, nonlinearity, loss function, optimizer and data loader through self-contained examples\n",
    "- Learn how to train a linear regression model purely in PyTorch\n",
    "\n",
    "###  General\n",
    "- This notebook was last tested on Python 3.6.9, PyTorch 1.2.0 and Matplotlib 3.1.2\n",
    "\n",
    "We would like to acknowledge the following materials which helped as a reference in preparing this tutorial:\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://github.com/jcjohnson/pytorch-examples\n",
    "- https://github.com/rguthrie3/DeepLearningForNLPInPytorch\n",
    "- https://github.com/hunkim/PyTorchZeroToAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch\n",
    "\n",
    "PyTorch is a Python based tool for scientific computing that provides three main features:\n",
    "- An n-dimensional Tensor, which is similar to numpy but can run on GPUs\n",
    "- Easily build big computational graphs for deep learning\n",
    "- Automatic differentiation for computing gradients for neural networks\n",
    "\n",
    "You can install PyTorch from: https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch's Tensor\n",
    "\n",
    "Tensor is an n-dimensional array, which is a generalization of a matrix that can be indexed in more than 2 dimensions. Tensor is similar to numpy that most of the operations in numpy object can be performed on a tensor object. However, tensor object benefits from strong GPU acceleration while numpy does not. All computations in deep learning are performed on tensors. Tensors also store optional information such as gradient and bookkeeping for computational graph. \n",
    "\n",
    "\n",
    "###  Tensor Creation\n",
    "Let us start by creating a tensor of size 5x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.1426e+22, 4.6241e+30, 1.0552e+24],\n",
      "        [5.5757e-02, 1.8728e+31, 1.4850e-41],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.6893e+19, 0.0000e+00, 3.6893e+19],\n",
      "        [1.8361e+25, 1.4603e-19, 1.6795e+08]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized tensor of size 5x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1591, 0.6392, 0.6140],\n",
      "        [0.1202, 0.2360, 0.3421],\n",
      "        [0.2057, 0.8977, 0.3761],\n",
      "        [0.0838, 0.7696, 0.4703],\n",
      "        [0.1749, 0.7360, 0.2767]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3) # a tensor filled with random numbers from a uniform distribution on the interval [0,1)\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor filled zeros and of data type (dtype) long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5000,  3.0000],\n",
      "        [ 3.2000, 13.0000],\n",
      "        [ 6.9000, 23.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[5.5, 3], [3.2, 13], [6.9, 23]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor based on existing tensor: (reusing properties of input tensor like dtype by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2092, -0.1732],\n",
      "        [-0.6729,  0.4692],\n",
      "        [ 0.7307, -0.2964]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn_like(x) \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the size of the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y.size())  # you can also use y.shape()\n",
    "print(y.size(1)) # get the number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 3D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.5000,  3.0000],\n",
      "         [ 3.2000, 13.0000],\n",
      "         [ 6.9000, 23.0000]],\n",
      "\n",
      "        [[ 2.1000,  3.3000],\n",
      "         [ 1.8000,  2.0000],\n",
      "         [ 5.2000, 20.0000]]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor([ [[5.5, 3], [3.2, 13], [6.9, 23]], [[2.1, 3.3], [1.8, 2], [5.2, 20]] ])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a 3D tensor anyway? Think about it like this. If you have a vector, indexing into the vector gives you a scalar. If you have a matrix, indexing into the matrix gives you a vector. If you have a 3D tensor, then indexing into the tensor gives you a matrix!\n",
    "\n",
    "The size of the 3D tensor will be 2x3x2 (in this example, 3D tensor is a collection of two 3x2 matrices). Let's print the size: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1000,  3.3000],\n",
      "        [ 1.8000,  2.0000],\n",
      "        [ 5.2000, 20.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(z[1]) # accesses the second dimension (matrix) whose size will be 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "print(z[1][1]) # accesses the second dimension of the second dimension (vector) whose size will be 1x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print(z[1][1][1]) # accesses the second dimension of the second dimension of the second dimension (scalar) whose size will be 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(z.dtype) # prints data type of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default data type of a tensor is Float. If you want an integer tensor, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "it = torch.tensor([3, 4], dtype=torch.int)\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Operations on a Tensor\n",
    "\n",
    "There are multiple syntaxes for operations. Let us take a look at the addition operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0196, 0.5918, 0.3331],\n",
      "        [0.9530, 0.0806, 0.2883],\n",
      "        [0.0092, 0.9906, 0.5546],\n",
      "        [0.8120, 0.7633, 0.2470],\n",
      "        [0.0873, 0.3698, 0.3920]])\n",
      "tensor([[0.7527, 0.2343, 0.0657],\n",
      "        [0.6871, 0.4556, 0.4106],\n",
      "        [0.9145, 0.5841, 0.7564],\n",
      "        [0.2241, 0.2805, 0.9887],\n",
      "        [0.5859, 0.0451, 0.6646]])\n"
     ]
    }
   ],
   "source": [
    "# let's create two tensors\n",
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "# let's print those two tensors\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7723, 0.8261, 0.3988],\n",
      "        [1.6401, 0.5362, 0.6989],\n",
      "        [0.9237, 1.5747, 1.3110],\n",
      "        [1.0361, 1.0437, 1.2357],\n",
      "        [0.6732, 0.4149, 1.0566]])\n",
      "tensor([[0.7723, 0.8261, 0.3988],\n",
      "        [1.6401, 0.5362, 0.6989],\n",
      "        [0.9237, 1.5747, 1.3110],\n",
      "        [1.0361, 1.0437, 1.2357],\n",
      "        [0.6732, 0.4149, 1.0566]])\n"
     ]
    }
   ],
   "source": [
    "# let's add them in two ways\n",
    "print(x + y) # method 1\n",
    "print(torch.add(x, y)) # method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7723, 0.8261, 0.3988],\n",
       "        [1.6401, 0.5362, 0.6989],\n",
       "        [0.9237, 1.5747, 1.3110],\n",
       "        [1.0361, 1.0437, 1.2357],\n",
       "        [0.6732, 0.4149, 1.0566]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x) # adds x to y (in-place) y := y + x  (method 3) or alternatively we can do y = torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operation that mutates a tensor in-place is post-fixed with an ``_``. For example: ``x.copy_(y)``, ``x.t_()`` (transpose), will change x.\n",
    "\n",
    "We can use standard NumPy-like indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0196, 0.5918, 0.3331],\n",
      "        [0.9530, 0.0806, 0.2883],\n",
      "        [0.0092, 0.9906, 0.5546],\n",
      "        [0.8120, 0.7633, 0.2470],\n",
      "        [0.0873, 0.3698, 0.3920]])\n",
      "tensor([0.5918, 0.0806, 0.9906, 0.7633, 0.3698])\n"
     ]
    }
   ],
   "source": [
    "print(x) # prints x whose size is 5x3\n",
    "print(x[:, 1]) # prints the second column of tensor whose size is 1x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us resize/reshape tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# let's print x's size\n",
    "print(x.size()) #  5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0196, 0.5918, 0.3331, 0.9530, 0.0806, 0.2883, 0.0092, 0.9906, 0.5546,\n",
      "        0.8120, 0.7633, 0.2470, 0.0873, 0.3698, 0.3920])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "# let's reshape x to a flat array\n",
    "print(x.view(15)) # print reshaped tensor\n",
    "print(x.view(15).size()) # print size of the reshaped tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us multiply two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create two tensors\n",
    "a = torch.randn(4, 1) \n",
    "b = torch.randn(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2494,  0.0679,  0.1170, -0.0736],\n",
       "        [ 0.2466,  0.0672,  0.1156, -0.0727],\n",
       "        [ 3.9342,  1.0715,  1.8451, -1.1602],\n",
       "        [ 1.4264,  0.3885,  0.6690, -0.4207]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's multiply each other: a x b \n",
    "torch.mul(a, b) # (4 x 1) x (1 x 4) = (4 x 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the mean of a tensor in one particular dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5870, -1.1412,  0.6950,  2.4109, -1.0589],\n",
      "        [-1.3645,  1.7250,  0.3351,  0.9016, -0.0672],\n",
      "        [ 0.6182, -1.4365,  0.1555, -1.0336,  0.9252]])\n"
     ]
    }
   ],
   "source": [
    "# let's create a tensor\n",
    "a = torch.randn(3, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8986,  0.3060, -0.1542])\n"
     ]
    }
   ],
   "source": [
    "# let's perform mean of the tensor over columns\n",
    "print(torch.mean(a, 1)) # reduce over columns (1) results in 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9469, -0.2842,  0.3952,  0.7596, -0.0670])\n"
     ]
    }
   ],
   "source": [
    "# let's perform mean of the tensor over rows\n",
    "print(torch.mean(a, 0)) # reduce over rows (0) results in 1x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the max of a tensor in one particular dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3999, -1.1410,  0.5982],\n",
      "        [-1.5726,  0.1573, -1.0897],\n",
      "        [-0.5734, -0.9301,  0.7407],\n",
      "        [-2.0365, -1.6990,  0.9722]])\n"
     ]
    }
   ],
   "source": [
    "# let's create a tensor\n",
    "a = torch.randn(4, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5982, 0.1573, 0.7407, 0.9722])\n",
      "tensor([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# let's identify maximum in each row\n",
    "values, indices = torch.max(a, 1) \n",
    "print(values) # values is the maximum value of each row of the input tensor. (1x4)\n",
    "print(indices) # indices is the index location of each maximum value found (argmax) (1x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at the list of supported Tensor functions here: https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "### NumPy Bridge \n",
    "We can easily convert a Torch tensor to a numpy array and vice versa.\n",
    "\n",
    "Let us convert a Torch Tensor to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# let's create a tensor\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# let's convert that tensor to numpy\n",
    "b = a.numpy() # converts Tensor to NumPy with a,b pointing to same memory locations\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# manipulate 'a' (changes will reflect in 'b')\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert a NumPy array to a Torch Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# let's create a numpy array\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let's convert to tensor\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# manipulate 'a' (changes will reflect in 'b')\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors\n",
    "\n",
    "We can use ``.to`` function to move Tensors onto any device. Generally, we move tensors to GPUs to accelerate the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")          # a CUDA device object\n",
    "  y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "  x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "  z = x + y\n",
    "  print(z)\n",
    "  print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graph and Automatic Differentiation\n",
    "\n",
    "Computation graph is an essential concept for efficient deep learning programming, because it allows you to not explicitly write the back propagation gradients yourselves. A computation graph is simply a specification of how your data is combined to give you the output. Since the graph totally specifies what parameters were involved with which operations, it contains enough information to compute derivatives. \n",
    "\n",
    "The ``autograd`` package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "Let us see this in more simple terms with some examples.\n",
    "\n",
    "Besides keeping track of size, data type and other things, Tensors can also keep track of how it was created. If you set its attribute ``.requires_grad`` as ``True``, it starts to track all operations on it.\n",
    "\n",
    "Let us see some example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n",
      "tensor([5., 1., 4.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "a = torch.tensor([1., 2., 3], requires_grad=True) \n",
    "b = torch.tensor([5., 1., 4], requires_grad=True) \n",
    "print(a) # 1x3\n",
    "print(b) # 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 3., 7.])\n"
     ]
    }
   ],
   "source": [
    "# add those tensors\n",
    "c = a + b # 1x3\n",
    "print(c.data) # 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x11f22e780>\n"
     ]
    }
   ],
   "source": [
    "# but c knows something extra.\n",
    "print(c.grad_fn) # c knows that it was a result of addition of two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x11f22ef28>\n"
     ]
    }
   ],
   "source": [
    "# sum all entries in c\n",
    "d = c.sum() # 1x1\n",
    "print(d)\n",
    "print(d.grad_fn) # d knows that it was a sum of all elements in a single tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``c`` knows that it was a result of addition of two tensors while ``d`` knows that it was a sum of all elements in a single tensor. Thus, a computation graph is simply a specification of how your data is combined to give you the output. You can imagine this computational graph as below:\n",
    "<img src=\"images/sl1_pytorch_cgraph_sum.jpg\" alt=\"computational graph example\" title=\"Example Computational Graph\" />\n",
    "\n",
    "Once we define the computational graph, we can call ``.backward()`` and have all the gradients computed automatically. The gradient for a tensor will be accumulated into ``.grad`` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "d.backward()\n",
    "print(a.grad) # 1x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can trust us that these gradients are correct. PyTorch lets you define arbitrary computation graph that is made up of tensor (``torch.tensor``) and modules (off-the-shelf layers from ``torch.nn`` and custom layers/models). \n",
    "\n",
    "Important Note: If you run the above block multiple times, the gradient will increment. That is because Pytorch accumulates the gradient into the ``.grad`` property, since for many models this is very convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearities, Nonlinearities and Loss functions\n",
    "\n",
    "A deep learning model is typically composed of linearities (affine transformation) and nonlinearities in a clever way. The nonlinearities makes the deep learning models powerful. The last node of the computational graph is typically a loss function (or objective function), which measure how far away the model prediction is from the actual target. PyTorch has most of the commonly used linearities, nonlinearities and loss functions already inbuilt into the library. Adding them to your computational graph is straightforward as we will see now.\n",
    "\n",
    "### Linearities\n",
    "Affine transformation is the commonly used linearity, which is a function $f(x)$ where $f(x) = A x + b$\n",
    "for a matrix $A$ and vectors $x, b$. The parameters to be learned here are $A$ and $b$. Often, $b$ is refered to as the bias term.\n",
    "\n",
    "Let us transform a sample data using affine transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# let's define a affine transformation based linearity layer\n",
    "linear_layer = torch.nn.Linear(5, 3) # maps from R^5 to R^3, parameters A, b\n",
    "print(linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print the parameters: A matrix and b vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0784,  0.0659, -0.1450, -0.0532, -0.1892],\n",
      "        [ 0.0027,  0.3824, -0.4171,  0.1136, -0.0211],\n",
      "        [ 0.2989,  0.2089,  0.0698, -0.0549, -0.3577]])\n",
      "tensor([ 0.0298,  0.2732, -0.1797])\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer.weight.data) # prints A  3x5\n",
    "print(linear_layer.bias.data) # prints b  1x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create some data and pass it to the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create data 'x'\n",
    "x = torch.randn(1, 5) # data is 1x5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4229, 0.1244, 0.0939]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# let's compute f(x) by passing x to the linear layer\n",
    "transformed_output = linear_layer(x)\n",
    "print(transformed_output)\n",
    "# print(linear_layer(torch.randn(1, 6))) # error: size mismatch, m1: [1 x 6], m2: [5 x 3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look into the other linear layers here: https://pytorch.org/docs/stable/nn.html#linear-layers\n",
    "\n",
    "### Nonlinearities\n",
    "Nonlinearities lets you build powerful deep learning models. For example, sigmoid nonlinearity squashes the input to be between 0 and 1. Sigmoid nonlinearity is defined by $\\sigma(x) = \\frac{1}{1+\\exp(-x)}$. \n",
    "\n",
    "Let us see an example for using sigmoid nonlinearity on sample input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define sigmoid layer\n",
    "sigmoid_layer = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8936, -0.2031,  0.8948, -0.3728, -1.1142]])\n"
     ]
    }
   ],
   "source": [
    "# let's define x\n",
    "x = torch.randn(1, 5) # data is 1x5.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1308, 0.4494, 0.7099, 0.4079, 0.2471]])\n"
     ]
    }
   ],
   "source": [
    "# let's pass x to sigmoid layer\n",
    "sigmoid_out = sigmoid_layer(x) # applies sigmoid element-wise results in 1x5 (doesn't change dimension)\n",
    "print(sigmoid_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used nonlinearity is softmax function, which rescales an n-dimensional input Tensor so that the elements of the n-dimensional output Tensor lie in the range $[0,1]$ and sum to 1. \n",
    "\n",
    "The softmax function is defined as, $softmax(x_i) = \\frac{\\exp{(x_i)}}{\\sum_j{\\exp{(x_j)}}}$\n",
    "\n",
    "Let us see an example for using softmax nonlinearity on sample input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a softmax layer\n",
    "softmax_layer = torch.nn.Softmax(dim=1) # row-wise softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4138,  1.7508,  0.1271, -1.0227,  0.5841]])\n"
     ]
    }
   ],
   "source": [
    "# let's create x\n",
    "x = torch.randn(1, 5) # data is 1x5.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pass x to the softmax_layer\n",
    "softmax_out = softmax_layer(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3124, 0.4377, 0.0863, 0.0273, 0.1363]])\n"
     ]
    }
   ],
   "source": [
    "# lets print softmax output\n",
    "print(softmax_out) # each entry is between 0 to 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# softmax output sums to 1.0\n",
    "print(softmax_out[0].sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the other nonlinear layers here: https://pytorch.org/docs/stable/nn.html#non-linear-activations-other\n",
    "\n",
    "### Loss function\n",
    "A loss function takes the (model prediction, target) pair of inputs, and computes a value that estimates how far away the model prediction is from the target.\n",
    "\n",
    "A simple loss is: ``nn.MSELoss`` which computes the mean-squared error between the model prediction ($\\hat{y}_i$) and the target ($y_i$). Mean Squared error can be written as, $(\\hat{y}_i - y_i)^{2}$\n",
    "\n",
    "Let us see an example for using MSELoss on output from Linear+softmax model and (randomly sampled) target (usually target is annotated by human but we create it synthetically in this tutorial for simplicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0343, -1.3723,  1.4747]])\n"
     ]
    }
   ],
   "source": [
    "# create data (input, target)\n",
    "data_input = torch.randn(1,3) # 1 example, 3 input features\n",
    "data_output = torch.randn(1,3) # 1 example, 3 target label\n",
    "print(data_output) # 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define linear and softmax layer\n",
    "linear_layer = torch.nn.Linear(3, 3)\n",
    "softmax_layer = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3419, 0.4189, 0.2392]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass the data_input through the model (computational graph)\n",
    "transformed_output = linear_layer(data_input) # maps from R^3 to R^1, parameters A, b i.e. maps 1x3 to 1x3\n",
    "model_output = softmax_layer(transformed_output)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2097, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# compute the MSELoss\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss = criterion(model_output, data_output) \n",
    "print(loss) # the MSE loss of 1 individual example  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can imagine the above computational graph to be like this:\n",
    "\n",
    "<img src=\"images/sl1_pytorch_softmax.jpg\" alt=\"computational graph example\" title=\"Example Computational Graph\" />\n",
    "\n",
    "You can look at the other loss layers here: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "## Optimization\n",
    "\n",
    "So far, we know:\n",
    "- how to define an arbitrary computation graph (model) with linearities, nonlinearities\n",
    "- how to add loss function to our model to measure the quality of models' predictions\n",
    "- how to use ``backward`` function to compute the gradients\n",
    "\n",
    "The only remaining piece of your PyTorch model is how to update (or learn) the weights (e.g., parameters $A, b$ of the linear layer). The commonly used optimization algorithm for neural networks is gradient descent (GD), which first randomly initializes the weight and changes the weight based on the update rule: $\\theta^{(t+1)} = \\theta^{(t)} - \\frac{1}{n} \\eta \\nabla_\\theta{L(\\theta)} $, where $\\eta$, $\\theta$ and $L(\\theta)$ corresponds to the learning rate (or step size), the parameters of the model (e.g., $A$ and $b$ put together) and the loss function over the parameters. $\\nabla_\\theta{L(\\theta)}$ correspond to the gradient which is calculated (resides in ``grads`` attribute of the tensor) when you call ``backward`` function. Therefore, the weight at the current step is equivalent to the weight at the previous step subtracted from multiplying the gradient (w.r.t weight in previous step) with the learning rate scaled by the number of examples ($n$) for this update.\n",
    "\n",
    "Let us see an example which updates the weight of our previous Linear+Softmax model with MSELoss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3466, -0.2849, -0.1186],\n",
      "        [ 0.5687, -0.1561,  0.0519],\n",
      "        [-0.0009, -0.4587, -0.4956]])\n"
     ]
    }
   ],
   "source": [
    "# get a reference to the weights (or parameters)\n",
    "model_weights = linear_layer.weight.data # note other layers in the previous graph do not have parameters\n",
    "print(model_weights) # prints model weights before GD update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0416,  0.0082,  0.0672],\n",
      "        [ 0.0980,  0.0192,  0.1582],\n",
      "        [-0.1396, -0.0274, -0.2254]])\n"
     ]
    }
   ],
   "source": [
    "# compute the gradients ($\\nabla_\\theta{L(\\theta)}$)\n",
    "# the whole graph is differentiated w.r.t. the loss, \n",
    "# and all Tensors in the graph that has requires_grad=True \n",
    "# will have their .grad Tensor accumulated with the gradient.\n",
    "loss.backward()\n",
    "print(linear_layer.weight.grad) # prints the gradient w.r.t each parameter for the given data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3424, -0.2857, -0.1254],\n",
      "        [ 0.5589, -0.1580,  0.0360],\n",
      "        [ 0.0131, -0.4559, -0.4730]])\n"
     ]
    }
   ],
   "source": [
    "# make the GD update\n",
    "model_weights = model_weights - (1/1.0) * 0.1 * linear_layer.weight.grad # 0.1 is the learning rate, 1.0 is the no. of examples for this update\n",
    "print(model_weights) # prints model weights after GD update which is 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, a GD update using only 1 training example is termed as stochastic gradient descent (SGD). If GD update uses multiple training examples (our update code actually uses 1 training example), then the optimization algorithm is termed as mini-batch gradient descent. A mini-batch gradient descent algorithm typically runs for several passes (or epochs) over your training data and at each pass, it grabs a mini-batch of training examples to perform the update. The size of the mini-batch and the learning rate are hyperparameters to be selected based on the performance of our model on the examples held out from the training data (or validation set).\n",
    "\n",
    "You can look at the overview of GD optimization algorithms here: https://ruder.io/optimizing-gradient-descent/index.html\n",
    "\n",
    "At this point in the tutorial, you have few more concepts to be learned such as ``torch.optim``, ``torch.utils.data.DataLoader`` and defining a model class by inheriting ``nn.Module`` to make you efficient in deep learning programming. Before you learn them, let us build a linear regression model and train it using synthetic data using all the concepts you have learned so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model - Full Pipeline\n",
    "\n",
    "### Problem\n",
    "In this section, we will focus on implementing the full pipeline for the linear regression model. Essentially, we will execute the following tasks:\n",
    "- generate synthetic data for linear regression with 1000 training examples each having 1 feature\n",
    "- define a linear regression model based on the computational graph:\n",
    "\n",
    "<img src=\"images/sl1_pytorch_linearregression.jpg\" alt=\"computational graph example for linear regression\" title=\"Example Computational Graph for Linear Regression\" width=\"400\" height=\"250\" />\n",
    "\n",
    "- plot the decision surface (based on random weights) before training\n",
    "- train the linear regression model using mini-batch GD with a batch size of 5 and learning rate of 0.01 for 5 epochs\n",
    "- report the MSE loss on the training examples after each epoch of training\n",
    "- plot the decision surface (based on trained weights) after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful imports\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# set the seed (allows reproducibility of the results)\n",
    "manual_seed = 123\n",
    "random.seed(manual_seed)\n",
    "np.random.seed(manual_seed) # allows us to reproduce results when using random generation on the numpy\n",
    "torch.manual_seed(manual_seed) # allows us to reproduce results when using random generation on the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "  torch.cuda.manual_seed(manual_seed) # allows us to reproduce results when using random generation on the gpu\n",
    "\n",
    "# hyperparameters\n",
    "MAX_EPOCHS = 5 # maximum number of training epochs\n",
    "LEARNING_RATE = 0.1 # learning rate for the optimization algorithm\n",
    "BATCH_SIZE = 5 # size of the mini-batch for gradient descent\n",
    "NUM_EXAMPLES = 1000 # total number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare synthetic training examples, 1000 of them each having 1 feature\n",
    "data_input = torch.randn(NUM_EXAMPLES, 1, requires_grad=False) # input features\n",
    "data_output = torch.randn(NUM_EXAMPLES, 1, requires_grad=False) # targets/labels\n",
    "for xi in range(NUM_EXAMPLES):\n",
    "  # make output some arbitrary function of x\n",
    "  data_output[xi] = data_input[xi].item()*2 + random.random() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define linear regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1) # takes an example with 1 feature and maps to 1 dimensional output\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision surface before training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# synthetic data\n",
    "plt.plot(data_input.numpy(), data_output.numpy(), 'ro', label='Original data') \n",
    "# model predictions on synthetic data\n",
    "plt.plot(data_input.numpy(), model(data_input).detach().numpy(), label='Fitted line') # \"detach()\" returns a tensor `detached’ from the current graph. \n",
    "plt.legend()\n",
    "plt.title(\"Decision surface before training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted line (based on random weights) is a poor fit to the underlying data.\n",
    "\n",
    "### Training procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skeleton of the training procedure is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in 1 to MAX_EPOCHS:\\n   for batch in batches(data): \\n      1. forward propagation - pass the batch through the model\\n      2. backward propagation - compute the gradients w.r.t each model parameter and update the model\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for epoch in 1 to MAX_EPOCHS:\n",
    "   for batch in batches(data): \n",
    "      1. forward propagation - pass the batch through the model\n",
    "      2. backward propagation - compute the gradients w.r.t each model parameter and update the model\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full training procedure is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2773\n",
      "Epoch [2/5], Loss: 0.0830\n",
      "Epoch [3/5], Loss: 0.0835\n",
      "Epoch [4/5], Loss: 0.0833\n",
      "Epoch [5/5], Loss: 0.0836\n"
     ]
    }
   ],
   "source": [
    "# placeholders for current batch\n",
    "batch_input = torch.randn(BATCH_SIZE, 1, requires_grad=False)\n",
    "batch_output = torch.randn(BATCH_SIZE, 1, requires_grad=False)\n",
    "num_batches = NUM_EXAMPLES // BATCH_SIZE # number of batches per epoch\n",
    "\n",
    "# kick-start the training\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "  # create a random indices from 1 to NUM_EXAMPLES\n",
    "  rand_indices = np.random.permutation(NUM_EXAMPLES)\n",
    "  total_loss = 0.0\n",
    "  for batch in range(num_batches):\n",
    "    # load the current batch\n",
    "    for bi in range(BATCH_SIZE):\n",
    "      cur_index = rand_indices[batch*BATCH_SIZE + bi]\n",
    "      batch_input[bi] = data_input[cur_index]\n",
    "      batch_output[bi] = data_output[cur_index]\n",
    "    \n",
    "    # forward propagation\n",
    "    # pass the data through the model\n",
    "    model_outputs = model(batch_input)\n",
    "    # compute the loss\n",
    "    cur_loss = criterion(model_outputs, batch_output)\n",
    "    total_loss += cur_loss.item()\n",
    "    \n",
    "    # backward propagation (compute the gradients and update the model)\n",
    "    # compute the gradients\n",
    "    cur_loss.backward()\n",
    "    # update the weights\n",
    "    model.weight.data = model.weight.data - (1.0/BATCH_SIZE) * LEARNING_RATE * model.weight.grad\n",
    "    model.bias.data = model.bias.data - (1.0/BATCH_SIZE) * LEARNING_RATE * model.bias.grad\n",
    "    # clear the buffer\n",
    "    model.weight.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "  # print the loss for every epoch\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, MAX_EPOCHS, total_loss/num_batches))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision surface after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_input.numpy(), data_output.numpy(), 'ro', label='Original data') # synthetic data\n",
    "plt.plot(data_input.numpy(), model(data_input).detach().numpy(), label='Fitted line') # model predictions on synthetic data\n",
    "plt.legend()\n",
    "plt.title(\"Decision surface after training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted line (based on learned weights) seems to be a better fit to the underlying data.\n",
    "\n",
    "Now that we have built our first PyTorch model and the training pipeline, we can look into modules in PyTorch which can help us write efficient deep learning code.\n",
    "\n",
    "## Miscellaneous PyTorch modules\n",
    "\n",
    "### DataLoader\n",
    "PyTorch's DataLoader ``torch.utils.data.DataLoader`` brings in several desirable advantages:\n",
    "- automatic batching (e.g., we managed the batches explicitly in our linear regression code which can be avoided)\n",
    "- multi-process data loading\n",
    "- customizing data loading order\n",
    "- automatic memory pinning and so on.\n",
    "\n",
    "Let us implement a simple dataloader for our linear regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# create a new class inheriting torch.utils.data.Dataset\n",
    "class LRDataset(Dataset):\n",
    "  \"\"\" LR Synthetic dataset.\"\"\"\n",
    "  # prepare synthetic training examples, 1000 of them each having 1 feature\n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    self.data_input = torch.randn(n, 1, requires_grad=False)\n",
    "    self.data_output = torch.randn(n, 1, requires_grad=False)\n",
    "    for xi in range(n):\n",
    "      # make output some arbitrary function of x\n",
    "      self.data_output[xi] = self.data_input[xi].item()*2 + random.random() \n",
    "  \n",
    "  # return input and output of a single example\n",
    "  def __getitem__(self, index):\n",
    "    return self.data_input[index], self.data_output[index]\n",
    "  \n",
    "  # return the total number of examples\n",
    "  def __len__(self):\n",
    "    return self.n\n",
    "\n",
    "# create the dataloader object\n",
    "dataset = LRDataset(NUM_EXAMPLES)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2) \n",
    "# num_workers refers to no. of subprocesses to use\n",
    "# for more details, look at https://pytorch.org/docs/stable/data.html#\n",
    "\n",
    "# iterate over the dataset for one epoch\n",
    "num_batches = 0\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "  input, output = data\n",
    "  if i == 0:\n",
    "    print(input.size(), output.size())\n",
    "  num_batches += 1\n",
    "print(num_batches) # prints the number of batches per epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom model class\n",
    "\n",
    "Wrapping the specifics of a model to a class will help us in extending our model swiftly. This is especially useful if our custom model has a lot of layers. We can define a custom model class by inheriting ``torch.nn.Module`` to wrap all the layers in our model as well as the forward propagation logic. \n",
    "\n",
    "Let us implement a custom model for our linear regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1]) torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "# create a custom model class inheriting torch.nn.Module\n",
    "class LRmodel(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    # In the constructor we define the layers for our model\n",
    "    super(LRmodel, self).__init__()\n",
    "    self.linear_layer = nn.Linear(1, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # In the forward function we define the forward propagation logic\n",
    "    out = self.linear_layer(x)\n",
    "    return out\n",
    "\n",
    "# instantiate an object from the model\n",
    "model = LRmodel()\n",
    "\n",
    "# create sample input\n",
    "input = torch.randn(100, 1)\n",
    "\n",
    "# pass the data through the model\n",
    "out = model(input)\n",
    "\n",
    "# print the size of the input and output\n",
    "print(input.size(), out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch's optim package\n",
    "\n",
    "``torch.optim`` is a PyTorch package implementing various optimization algorithms like SGD, Rmsprop and Adam. \n",
    "\n",
    "Let us implement the mini-batch GD algorithm using optim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1976]])\n",
      "tensor([-0.1351])\n",
      "tensor([[0.1856]])\n",
      "tensor([-0.0707])\n"
     ]
    }
   ],
   "source": [
    "# create an instance of SGD with required hyperparameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# print weights before update\n",
    "for param in model.parameters():\n",
    "  print(param.data)\n",
    "\n",
    "# create sample input and output\n",
    "input = torch.randn(100, 1)\n",
    "output = torch.randn(100, 1)\n",
    "\n",
    "# forward pass\n",
    "prediction = model(input)\n",
    "loss = criterion(prediction, output)\n",
    "# backward pass\n",
    "optimizer.zero_grad() # clears the gradient buffer\n",
    "loss.backward() # performs the backward pass\n",
    "optimizer.step() # update the weights\n",
    "\n",
    "# print weights before update\n",
    "for param in model.parameters():\n",
    "  print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look for other available optimization algorithms here: https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "## Adding dataloader, custom model and optim to our linear regression code\n",
    "\n",
    "In this section we will refine our linear regression code with the previously discussed modules, specifically DataLoader, custom model and optim.\n",
    "\n",
    "The self-contained full code is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1252\n",
      "Epoch [2/5], Loss: 0.0861\n",
      "Epoch [3/5], Loss: 0.0857\n",
      "Epoch [4/5], Loss: 0.0851\n",
      "Epoch [5/5], Loss: 0.0861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all the necessary imports\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "# set the seed\n",
    "manual_seed = 123\n",
    "random.seed(manual_seed)\n",
    "np.random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "  torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "\"\"\"\n",
    "create a new class inheriting torch.utils.data.Dataset\n",
    "\"\"\"\n",
    "class LRDataset(Dataset):\n",
    "  \"\"\" LR Synthetic dataset.\"\"\"\n",
    "  # prepare synthetic training examples, 1000 of them each having 1 feature\n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    self.data_input = torch.randn(n, 1, requires_grad=False, device=device)\n",
    "    self.data_output = torch.randn(n, 1, requires_grad=False, device=device)\n",
    "    for xi in range(n):\n",
    "      # make output some arbitrary function of x\n",
    "      self.data_output[xi] = self.data_input[xi].item()*2 + random.random() \n",
    "  \n",
    "  # return input and output of a single example\n",
    "  def __getitem__(self, index):\n",
    "    return self.data_input[index], self.data_output[index]\n",
    "  \n",
    "  # return the total number of examples\n",
    "  def __len__(self):\n",
    "    return self.n\n",
    "\n",
    "\"\"\"\n",
    "create a custom model class inheriting torch.nn.Module\n",
    "\"\"\"\n",
    "class LRmodel(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    # In the constructor we define the layers for our model\n",
    "    super(LRmodel, self).__init__()\n",
    "    self.linear_layer = nn.Linear(1, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # In the forward function we define the forward propagation logic\n",
    "    out = self.linear_layer(x)\n",
    "    return out\n",
    "\n",
    "# hyperparameters\n",
    "MAX_EPOCHS = 5\n",
    "LEARNING_RATE = 0.1\n",
    "BATCH_SIZE = 5\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "# create the dataloader instance\n",
    "dataset = LRDataset(NUM_EXAMPLES)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2) \n",
    "\n",
    "# define the model\n",
    "model = LRmodel()\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create an instance of SGD with required hyperparameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# print the decision surface before training\n",
    "plt.plot(dataset.data_input.numpy(), dataset.data_output.numpy(), 'ro', label='Original data') # synthetic data\n",
    "plt.plot(dataset.data_input.numpy(), model(dataset.data_input).detach().numpy(), label='Fitted line') # model predictions on synthetic data\n",
    "plt.legend()\n",
    "plt.title(\"Decision surface before training\")\n",
    "plt.show()\n",
    "\n",
    "# start the training\n",
    "num_batches = NUM_EXAMPLES // BATCH_SIZE # number of batches per epoch\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "  total_loss = 0.0\n",
    "  # iterate throught the data loader\n",
    "  for batch in train_loader:\n",
    "    # load the current batch\n",
    "    batch_input, batch_output = batch\n",
    "    \n",
    "    # forward propagation\n",
    "    # pass the data through the model\n",
    "    model_outputs = model(batch_input)\n",
    "    # compute the loss\n",
    "    cur_loss = criterion(model_outputs, batch_output)\n",
    "    total_loss += cur_loss.item()\n",
    "    \n",
    "    # backward propagation (compute the gradients and update the model)\n",
    "    # clear the buffer\n",
    "    optimizer.zero_grad()\n",
    "    # compute the gradients\n",
    "    cur_loss.backward()\n",
    "    # update the weights\n",
    "    optimizer.step()\n",
    "    \n",
    "  # print the loss for every epoch\n",
    "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, MAX_EPOCHS, total_loss/num_batches))\n",
    "\n",
    "# print the decision surface after training\n",
    "plt.plot(dataset.data_input.numpy(), dataset.data_output.numpy(), 'ro', label='Original data') # synthetic data\n",
    "plt.plot(dataset.data_input.numpy(), model(dataset.data_input).detach().numpy(), label='Fitted line') # model predictions on synthetic data\n",
    "plt.legend()\n",
    "plt.title(\"Decision surface after training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ctrl_transformers)",
   "language": "python",
   "name": "ctrl_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
